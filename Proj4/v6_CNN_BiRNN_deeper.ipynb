{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_BiRNN for Speech Enhancement (Spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.0.8\n",
      "tensorflow 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "## To get helper functions from another folder\n",
    "# sys.path.insert(0, '../') # if _helper_basics_ is in previous folder\n",
    "now_i_am_at = 'home' # home dso test\n",
    "if now_i_am_at=='home': sys.path.insert(0, 'E:/Leonard HDD/Dropbox/DSO/Tasks/')\n",
    "elif now_i_am_at=='dso': sys.path.insert(0, 'D:/Dropbox/DSO/Tasks')\n",
    "\n",
    "from _helper_basics_ import *\n",
    "from _helper_enhancement_ import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print('keras',      keras.__version__)\n",
    "print('tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Leonard HDD/Dropbox/Speech Audio Text/3) Dataset/Reverb_2\\noisy_trainset_28spk_wav\n",
      "E:/Leonard HDD/Dropbox/Speech Audio Text/3) Dataset/Reverb_2\\clean_trainset_28spk_wav\n",
      "save_data_dir E:/Leonard HDD/Dropbox/DSO/Tasks/Dereverberation\\Reverb_Data_28spk_wav\n",
      "Noise_Mag_dir E:/Leonard HDD/Dropbox/DSO/Tasks/Dereverberation\\Reverb_Data_28spk_wav\\Noise_Mag\n",
      "Noise_Pha_dir E:/Leonard HDD/Dropbox/DSO/Tasks/Dereverberation\\Reverb_Data_28spk_wav\\Noise_Pha\n",
      "Clean_Mag_dir E:/Leonard HDD/Dropbox/DSO/Tasks/Dereverberation\\Reverb_Data_28spk_wav\\Clean_Mag\n",
      "Clean_Pha_dir E:/Leonard HDD/Dropbox/DSO/Tasks/Dereverberation\\Reverb_Data_28spk_wav\\Clean_Pha\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = 16000\n",
    "\n",
    "## Original wavfiles\n",
    "data_dir = 'E:/Leonard HDD/Dropbox/Speech Audio Text/3) Dataset/Reverb_2'\n",
    "noisy_dir = os.path.join(data_dir, 'noisy_trainset_28spk_wav')\n",
    "clean_dir = os.path.join(data_dir, 'clean_trainset_28spk_wav')\n",
    "print(noisy_dir)\n",
    "print(clean_dir)\n",
    "\n",
    "## Saving\n",
    "pwd = 'E:/Leonard HDD/Dropbox/DSO/Tasks/Dereverberation'\n",
    "save_data_dir = os.path.join(pwd, 'Reverb_Data_28spk_wav')\n",
    "Noise_Mag_dir = os.path.join(save_data_dir, 'Noise_Mag')\n",
    "Noise_Pha_dir = os.path.join(save_data_dir, 'Noise_Pha')\n",
    "Clean_Mag_dir = os.path.join(save_data_dir, 'Clean_Mag')\n",
    "Clean_Pha_dir = os.path.join(save_data_dir, 'Clean_Pha')\n",
    "print('save_data_dir',save_data_dir)\n",
    "print('Noise_Mag_dir',Noise_Mag_dir)\n",
    "print('Noise_Pha_dir',Noise_Pha_dir)\n",
    "print('Clean_Mag_dir',Clean_Mag_dir)\n",
    "print('Clean_Pha_dir',Clean_Pha_dir)\n",
    "\n",
    "noise_files_list = []\n",
    "for noise_wav in glob.glob( os.path.join(noisy_dir, '*.wav') ):\n",
    "    noise_wav_term = noise_wav[len(noisy_dir)+1:len(noise_wav)-4]\n",
    "    noise_files_list.append(noise_wav_term)\n",
    "len(noise_files_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Time taken to read from disk for 1 Epoch\n",
    "start_time = time.time()\n",
    "for _ in range(1000):\n",
    "    get_XY_batch(batch_size)\n",
    "time.time() - start_time\n",
    "\n",
    "# 39.65008568763733 seconds taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Archi_dir = \"v6__CNNBiRNN_deeper/\"\n",
    "Weights_path = Archi_dir+\"Logs/\"\n",
    "Ckpt_Mod_Weights_fold = Archi_dir+\"Checkpoint_Model_Weights/\"\n",
    "plot_path_dir = Archi_dir+'Plots/'\n",
    "if not os.path.exists(Archi_dir): os.mkdir(Archi_dir)\n",
    "if not os.path.exists(Weights_path): os.mkdir(Weights_path)\n",
    "if not os.path.exists(Ckpt_Mod_Weights_fold): os.mkdir(Ckpt_Mod_Weights_fold)\n",
    "if not os.path.exists(plot_path_dir): os.mkdir(plot_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Input (InputLayer)               (None, 129, 128, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "0_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   16          Input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "0_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   8           Input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "0_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  32          Input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "0_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        0_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "0_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         0_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "0_Inception (Concatenate)        (None, 129, 128, 40)  0           0_1a_Conv2D[0][0]                \n",
      "                                                                   0_3_Conv2D[0][0]                 \n",
      "                                                                   0_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "1_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         0_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "1_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         0_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "1_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         0_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "1_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        1_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "1_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         1_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "1_Inception (Concatenate)        (None, 129, 128, 40)  0           1_1a_Conv2D[0][0]                \n",
      "                                                                   1_3_Conv2D[0][0]                 \n",
      "                                                                   1_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "2_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         1_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "2_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         1_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "2_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         1_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "2_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        2_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "2_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         2_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "2_Inception (Concatenate)        (None, 129, 128, 40)  0           2_1a_Conv2D[0][0]                \n",
      "                                                                   2_3_Conv2D[0][0]                 \n",
      "                                                                   2_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "3_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         2_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "3_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         2_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "3_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         2_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "3_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        3_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "3_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         3_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "3_Inception (Concatenate)        (None, 129, 128, 40)  0           3_1a_Conv2D[0][0]                \n",
      "                                                                   3_3_Conv2D[0][0]                 \n",
      "                                                                   3_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "4_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         3_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "4_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         3_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "4_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         3_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "4_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        4_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "4_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         4_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "4_Inception (Concatenate)        (None, 129, 128, 40)  0           4_1a_Conv2D[0][0]                \n",
      "                                                                   4_3_Conv2D[0][0]                 \n",
      "                                                                   4_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "5_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         4_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "5_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         4_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "5_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         4_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "5_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        5_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "5_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         5_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "5_Inception (Concatenate)        (None, 129, 128, 40)  0           5_1a_Conv2D[0][0]                \n",
      "                                                                   5_3_Conv2D[0][0]                 \n",
      "                                                                   5_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "6_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         5_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "6_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         5_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "6_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         5_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "6_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        6_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "6_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         6_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "6_Inception (Concatenate)        (None, 129, 128, 40)  0           6_1a_Conv2D[0][0]                \n",
      "                                                                   6_3_Conv2D[0][0]                 \n",
      "                                                                   6_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "7_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         6_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "7_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         6_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "7_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         6_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "7_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        7_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "7_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         7_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "7_Inception (Concatenate)        (None, 129, 128, 40)  0           7_1a_Conv2D[0][0]                \n",
      "                                                                   7_3_Conv2D[0][0]                 \n",
      "                                                                   7_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "8_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         7_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "8_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         7_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "8_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         7_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "8_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        8_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "8_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         8_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "8_Inception (Concatenate)        (None, 129, 128, 40)  0           8_1a_Conv2D[0][0]                \n",
      "                                                                   8_3_Conv2D[0][0]                 \n",
      "                                                                   8_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "9_1b_Conv2D (Conv2D)             (None, 129, 128, 8)   328         8_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "9_1c_Conv2D (Conv2D)             (None, 129, 128, 4)   164         8_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "9_1a_Conv2D (Conv2D)             (None, 129, 128, 16)  656         8_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "9_3_Conv2D (Conv2D)              (None, 129, 128, 16)  1168        9_1b_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "9_5_Conv2D (Conv2D)              (None, 129, 128, 8)   808         9_1c_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "9_Inception (Concatenate)        (None, 129, 128, 40)  0           9_1a_Conv2D[0][0]                \n",
      "                                                                   9_3_Conv2D[0][0]                 \n",
      "                                                                   9_5_Conv2D[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "10_1b_Conv2D (Conv2D)            (None, 129, 128, 8)   328         9_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "10_1c_Conv2D (Conv2D)            (None, 129, 128, 4)   164         9_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "10_1a_Conv2D (Conv2D)            (None, 129, 128, 16)  656         9_Inception[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "10_3_Conv2D (Conv2D)             (None, 129, 128, 16)  1168        10_1b_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "10_5_Conv2D (Conv2D)             (None, 129, 128, 8)   808         10_1c_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "10_Inception (Concatenate)       (None, 129, 128, 40)  0           10_1a_Conv2D[0][0]               \n",
      "                                                                   10_3_Conv2D[0][0]                \n",
      "                                                                   10_5_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "11_1b_Conv2D (Conv2D)            (None, 129, 128, 8)   328         10_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "11_1c_Conv2D (Conv2D)            (None, 129, 128, 4)   164         10_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "11_1a_Conv2D (Conv2D)            (None, 129, 128, 16)  656         10_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "11_3_Conv2D (Conv2D)             (None, 129, 128, 16)  1168        11_1b_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "11_5_Conv2D (Conv2D)             (None, 129, 128, 8)   808         11_1c_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "11_Inception (Concatenate)       (None, 129, 128, 40)  0           11_1a_Conv2D[0][0]               \n",
      "                                                                   11_3_Conv2D[0][0]                \n",
      "                                                                   11_5_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "12_1b_Conv2D (Conv2D)            (None, 129, 128, 8)   328         11_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "12_1c_Conv2D (Conv2D)            (None, 129, 128, 4)   164         11_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "12_1a_Conv2D (Conv2D)            (None, 129, 128, 16)  656         11_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "12_3_Conv2D (Conv2D)             (None, 129, 128, 16)  1168        12_1b_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "12_5_Conv2D (Conv2D)             (None, 129, 128, 8)   808         12_1c_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "12_Inception (Concatenate)       (None, 129, 128, 40)  0           12_1a_Conv2D[0][0]               \n",
      "                                                                   12_3_Conv2D[0][0]                \n",
      "                                                                   12_5_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "13_1b_Conv2D (Conv2D)            (None, 129, 128, 8)   328         12_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "13_1c_Conv2D (Conv2D)            (None, 129, 128, 4)   164         12_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "13_1a_Conv2D (Conv2D)            (None, 129, 128, 16)  656         12_Inception[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "13_3_Conv2D (Conv2D)             (None, 129, 128, 16)  1168        13_1b_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "13_5_Conv2D (Conv2D)             (None, 129, 128, 8)   808         13_1c_Conv2D[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "13_Inception (Concatenate)       (None, 129, 128, 40)  0           13_1a_Conv2D[0][0]               \n",
      "                                                                   13_3_Conv2D[0][0]                \n",
      "                                                                   13_5_Conv2D[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "14_Conv2D (Conv2D)               (None, 129, 128, 1)   361         13_Inception[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 43,005\n",
      "Trainable params: 43,005\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 129)          0         \n",
      "_________________________________________________________________\n",
      "0_Bi_GRU (Bidirectional)     (None, 128, 258)          200466    \n",
      "_________________________________________________________________\n",
      "1_GRU (GRU)                  (None, 128, 129)          150156    \n",
      "=================================================================\n",
      "Total params: 350,622\n",
      "Trainable params: 350,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 129, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "Conv_SubNet (Model)          (None, 129, 128, 1)       43005     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 129, 128)          0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 128, 129)          0         \n",
      "_________________________________________________________________\n",
      "Bi_RNN_SubNet (Model)        (None, 128, 129)          350622    \n",
      "_________________________________________________________________\n",
      "permute_2 (Permute)          (None, 129, 128)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 129, 128, 1)       0         \n",
      "=================================================================\n",
      "Total params: 393,627\n",
      "Trainable params: 393,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_freq,num_time,num_channel    = 129,128,1\n",
    "\n",
    "filt_incept_list = [[16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8],\n",
    "                    [16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8],\n",
    "                    [16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8],\n",
    "                    [16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8],\n",
    "                    [16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8],\n",
    "                    [16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8],\n",
    "                    [16, 8, 4, 16, 8], \n",
    "                    [16, 8, 4, 16, 8]]\n",
    "\n",
    "# filt_incept_list = [[16, 8, 4, 16, 8], \n",
    "#                     [32, 16, 8, 32, 16],\n",
    "#                     [32, 16, 8, 32, 16], \n",
    "#                     [32, 16, 8, 32, 16],\n",
    "#                     [32, 16, 8, 32, 16], \n",
    "#                     [32, 16, 8, 32, 16],\n",
    "#                     [32, 16, 8, 32, 16], \n",
    "#                     [16, 8, 4, 16, 8]]\n",
    "\n",
    "# filt_incept_list = [[16, 8, 8, 16, 16], \n",
    "#                     [32, 16, 16, 32, 32],\n",
    "#                     [32, 16, 16, 32, 32], \n",
    "#                     [16, 8, 8, 16, 16]]\n",
    "rnn_neu_list = [num_freq,num_freq]\n",
    "########################### Printing information ###########################\n",
    "build_model(num_freq,num_time,num_channel, filt_incept_list, rnn_neu_list,reg_l2=0.).summary()\n",
    "# model = build_model(num_freq,num_time,num_channel, filt_incept_list, rnn_neu_list,reg_l2=0.)\n",
    "# model.summary()\n",
    "# print_model_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay 0\n",
      "steps_per_epoch 500\n",
      "epochs 150\n",
      "batch_size 8\n"
     ]
    }
   ],
   "source": [
    "Folder_det = [noisy_dir,clean_dir,Noise_Mag_dir,Noise_Pha_dir,Clean_Mag_dir,Clean_Pha_dir]\n",
    "num_Det = [num_freq,num_time,num_channel]\n",
    "######################## Training Parameters ###############################\n",
    "decay = 0;          \tprint('decay',decay)\n",
    "steps_per_epoch = 500;\tprint('steps_per_epoch',steps_per_epoch)\n",
    "epochs = 150;\t\t\tprint('epochs',epochs)\n",
    "batch_size = 8;   \t\tprint('batch_size',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6\n",
    "## 14 Inception + 1 Conv + 1 BiGRU + 1 GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial training : train_model_v6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 129, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "Conv_SubNet (Model)          (None, 129, 128, 1)       43005     \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 129, 128)          0         \n",
      "_________________________________________________________________\n",
      "permute_13 (Permute)         (None, 128, 129)          0         \n",
      "_________________________________________________________________\n",
      "Bi_RNN_SubNet (Model)        (None, 128, 129)          350622    \n",
      "_________________________________________________________________\n",
      "permute_14 (Permute)         (None, 129, 128)          0         \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (None, 129, 128, 1)       0         \n",
      "=================================================================\n",
      "Total params: 393,627\n",
      "Trainable params: 393,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "learning_rate 0.001\n",
      "ckpt_path :  v6__CNNBiRNN_deeper/Checkpoint_Model_Weights/v6_1/weights_v6_1_Epoch-{epoch:04d}_L-{loss:.2f}.hdf5 \n",
      "\n",
      "Epoch 1/100\n",
      "p239_068\n",
      "p269_325\n",
      "p259_390\n",
      "p267_273\n",
      "p259_396\n",
      "p270_061\n",
      "p270_060\n",
      "p239_163\n",
      "p267_217\n",
      "p286_188\n",
      "p227_319\n",
      "  1/500 [..............................] - ETA: 4595s - loss: 0.1904p259_292\n",
      "  2/500 [..............................] - ETA: 2718s - loss: 0.3471p231_395\n",
      "  3/500 [..............................] - ETA: 2085s - loss: 0.2783p228_035\n",
      "  4/500 [..............................] - ETA: 1772s - loss: 0.3635p236_312\n",
      "  5/500 [..............................] - ETA: 1587s - loss: 0.3427p250_135\n",
      "  6/500 [..............................] - ETA: 1462s - loss: 0.4212p274_243\n",
      "  7/500 [..............................] - ETA: 1368s - loss: 0.4790p270_121\n",
      "  8/500 [..............................] - ETA: 1297s - loss: 0.4560p273_262\n",
      "  9/500 [..............................] - ETA: 1243s - loss: 0.4401p231_126\n",
      " 10/500 [..............................] - ETA: 1198s - loss: 0.4314p267_364\n",
      " 11/500 [..............................] - ETA: 1161s - loss: 0.4148p244_309\n",
      " 12/500 [..............................] - ETA: 1130s - loss: 0.4095p254_279\n",
      " 13/500 [..............................] - ETA: 1103s - loss: 0.4202p269_270\n",
      " 14/500 [..............................] - ETA: 1081s - loss: 0.4142p256_160\n",
      " 15/500 [..............................] - ETA: 1061s - loss: 0.4169p227_109\n",
      " 16/500 [..............................] - ETA: 1043s - loss: 0.4095p256_310\n",
      " 17/500 [>.............................] - ETA: 1028s - loss: 0.3963p270_048\n",
      " 18/500 [>.............................] - ETA: 1013s - loss: 0.4007p259_386\n",
      " 19/500 [>.............................] - ETA: 1001s - loss: 0.4188p278_037\n",
      " 20/500 [>.............................] - ETA: 992s - loss: 0.4240 p239_425\n",
      " 21/500 [>.............................] - ETA: 981s - loss: 0.4258p239_025\n",
      " 22/500 [>.............................] - ETA: 971s - loss: 0.4299p239_192\n",
      " 23/500 [>.............................] - ETA: 962s - loss: 0.4232p282_149\n",
      " 24/500 [>.............................] - ETA: 953s - loss: 0.4386p282_007\n",
      " 25/500 [>.............................] - ETA: 945s - loss: 0.4319p259_147\n",
      " 26/500 [>.............................] - ETA: 938s - loss: 0.4244p228_074\n",
      " 27/500 [>.............................] - ETA: 930s - loss: 0.4271p250_065\n",
      " 28/500 [>.............................] - ETA: 925s - loss: 0.4300p236_006\n",
      " 29/500 [>.............................] - ETA: 918s - loss: 0.4274p227_017\n",
      " 30/500 [>.............................] - ETA: 912s - loss: 0.4213p244_226\n",
      " 31/500 [>.............................] - ETA: 906s - loss: 0.4271p278_073\n",
      " 32/500 [>.............................] - ETA: 900s - loss: 0.4239p228_260\n",
      " 33/500 [>.............................] - ETA: 895s - loss: 0.4216p259_133\n",
      " 34/500 [=>............................] - ETA: 890s - loss: 0.4178p286_150\n",
      " 35/500 [=>............................] - ETA: 885s - loss: 0.4163p227_175\n",
      " 36/500 [=>............................] - ETA: 881s - loss: 0.4143p276_316\n",
      " 37/500 [=>............................] - ETA: 876s - loss: 0.4152p231_361\n",
      " 38/500 [=>............................] - ETA: 873s - loss: 0.4126p244_160\n",
      " 39/500 [=>............................] - ETA: 868s - loss: 0.4167p274_136\n",
      " 40/500 [=>............................] - ETA: 864s - loss: 0.4110p258_249\n",
      " 41/500 [=>............................] - ETA: 860s - loss: 0.4136p227_111\n",
      " 42/500 [=>............................] - ETA: 856s - loss: 0.4107p256_112\n",
      " 43/500 [=>............................] - ETA: 852s - loss: 0.4123p286_261\n",
      " 44/500 [=>............................] - ETA: 849s - loss: 0.4105p228_084\n",
      " 45/500 [=>............................] - ETA: 845s - loss: 0.4192p273_152\n",
      " 46/500 [=>............................] - ETA: 841s - loss: 0.4114p243_335\n",
      " 47/500 [=>............................] - ETA: 838s - loss: 0.4112p226_114\n",
      " 48/500 [=>............................] - ETA: 834s - loss: 0.4118p258_002\n",
      " 49/500 [=>............................] - ETA: 831s - loss: 0.4164p236_335\n",
      " 50/500 [==>...........................] - ETA: 827s - loss: 0.4138p243_046\n",
      " 51/500 [==>...........................] - ETA: 824s - loss: 0.4080p250_266\n",
      " 52/500 [==>...........................] - ETA: 821s - loss: 0.4028p277_343\n",
      " 53/500 [==>...........................] - ETA: 818s - loss: 0.4051p274_452\n",
      " 54/500 [==>...........................] - ETA: 815s - loss: 0.4026p256_075\n",
      " 55/500 [==>...........................] - ETA: 812s - loss: 0.4034p258_113\n",
      " 56/500 [==>...........................] - ETA: 809s - loss: 0.3996p256_179\n",
      " 57/500 [==>...........................] - ETA: 806s - loss: 0.3949p256_164\n",
      " 58/500 [==>...........................] - ETA: 803s - loss: 0.3903p231_193\n",
      " 59/500 [==>...........................] - ETA: 800s - loss: 0.3879p228_062\n",
      " 60/500 [==>...........................] - ETA: 797s - loss: 0.3858p273_097\n",
      " 61/500 [==>...........................] - ETA: 794s - loss: 0.3842p270_446\n",
      " 62/500 [==>...........................] - ETA: 791s - loss: 0.3810p282_359\n",
      " 63/500 [==>...........................] - ETA: 788s - loss: 0.3806p236_135\n",
      " 64/500 [==>...........................] - ETA: 786s - loss: 0.3755p270_425\n",
      " 65/500 [==>...........................] - ETA: 783s - loss: 0.3721p230_270\n",
      " 66/500 [==>...........................] - ETA: 781s - loss: 0.3708p274_040\n",
      " 67/500 [===>..........................] - ETA: 778s - loss: 0.3676p243_096\n",
      " 68/500 [===>..........................] - ETA: 775s - loss: 0.3660p282_028\n",
      " 69/500 [===>..........................] - ETA: 773s - loss: 0.3654p270_256\n",
      " 70/500 [===>..........................] - ETA: 770s - loss: 0.3652p269_179\n",
      " 71/500 [===>..........................] - ETA: 767s - loss: 0.3656p230_070\n",
      " 72/500 [===>..........................] - ETA: 765s - loss: 0.3676p236_134\n",
      " 73/500 [===>..........................] - ETA: 763s - loss: 0.3647p236_061\n",
      " 74/500 [===>..........................] - ETA: 760s - loss: 0.3610p269_094\n",
      " 75/500 [===>..........................] - ETA: 758s - loss: 0.3623p231_373\n",
      " 76/500 [===>..........................] - ETA: 755s - loss: 0.3591p233_080\n",
      " 77/500 [===>..........................] - ETA: 753s - loss: 0.3598p273_331\n",
      " 78/500 [===>..........................] - ETA: 751s - loss: 0.3566p276_364\n",
      " 79/500 [===>..........................] - ETA: 748s - loss: 0.3555p270_144\n",
      " 80/500 [===>..........................] - ETA: 746s - loss: 0.3580p268_192\n",
      " 81/500 [===>..........................] - ETA: 744s - loss: 0.3598p226_329\n",
      " 82/500 [===>..........................] - ETA: 742s - loss: 0.3581p286_047\n",
      " 83/500 [===>..........................] - ETA: 740s - loss: 0.3573p274_323\n",
      " 84/500 [====>.........................] - ETA: 737s - loss: 0.3562p239_107\n",
      " 85/500 [====>.........................] - ETA: 735s - loss: 0.3550p258_293\n",
      " 86/500 [====>.........................] - ETA: 733s - loss: 0.3552p244_400\n",
      " 87/500 [====>.........................] - ETA: 731s - loss: 0.3560p274_273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/500 [====>.........................] - ETA: 729s - loss: 0.3559p267_202\n",
      " 89/500 [====>.........................] - ETA: 726s - loss: 0.3549p273_268\n",
      " 90/500 [====>.........................] - ETA: 724s - loss: 0.3554p274_290\n",
      " 91/500 [====>.........................] - ETA: 722s - loss: 0.3549p239_471\n",
      " 92/500 [====>.........................] - ETA: 720s - loss: 0.3536p256_028\n",
      " 93/500 [====>.........................] - ETA: 718s - loss: 0.3538p287_021\n",
      " 94/500 [====>.........................] - ETA: 715s - loss: 0.3519p277_020\n",
      " 95/500 [====>.........................] - ETA: 713s - loss: 0.3512p274_207\n",
      " 96/500 [====>.........................] - ETA: 711s - loss: 0.3497p254_058\n",
      " 97/500 [====>.........................] - ETA: 709s - loss: 0.3471p244_167\n",
      " 98/500 [====>.........................] - ETA: 707s - loss: 0.3456p239_297\n",
      " 99/500 [====>.........................] - ETA: 704s - loss: 0.3440p258_321\n",
      "100/500 [=====>........................] - ETA: 702s - loss: 0.3448p287_114\n",
      "101/500 [=====>........................] - ETA: 700s - loss: 0.3427p231_111\n",
      "102/500 [=====>........................] - ETA: 698s - loss: 0.3411p239_344\n",
      "103/500 [=====>........................] - ETA: 696s - loss: 0.3384p267_236\n",
      "104/500 [=====>........................] - ETA: 694s - loss: 0.3363p273_271\n",
      "105/500 [=====>........................] - ETA: 692s - loss: 0.3354p287_221\n",
      "106/500 [=====>........................] - ETA: 690s - loss: 0.3336p250_434\n",
      "107/500 [=====>........................] - ETA: 688s - loss: 0.3404p279_092\n",
      "108/500 [=====>........................] - ETA: 686s - loss: 0.3446p259_245\n",
      "109/500 [=====>........................] - ETA: 684s - loss: 0.3451p250_200\n",
      "110/500 [=====>........................] - ETA: 682s - loss: 0.3440p231_314\n",
      "111/500 [=====>........................] - ETA: 680s - loss: 0.3440p274_256\n",
      "112/500 [=====>........................] - ETA: 678s - loss: 0.3466p282_179\n",
      "113/500 [=====>........................] - ETA: 676s - loss: 0.3452p276_282\n",
      "114/500 [=====>........................] - ETA: 674s - loss: 0.3465p259_133\n",
      "115/500 [=====>........................] - ETA: 671s - loss: 0.3476p244_302\n",
      "116/500 [=====>........................] - ETA: 669s - loss: 0.3459p277_431\n",
      "117/500 [======>.......................] - ETA: 667s - loss: 0.3468p243_081\n",
      "118/500 [======>.......................] - ETA: 665s - loss: 0.3464p270_299\n",
      "119/500 [======>.......................] - ETA: 663s - loss: 0.3452p273_114\n",
      "120/500 [======>.......................] - ETA: 661s - loss: 0.3462p282_289\n",
      "121/500 [======>.......................] - ETA: 660s - loss: 0.3461p274_319\n",
      "122/500 [======>.......................] - ETA: 658s - loss: 0.3463p274_021\n",
      "123/500 [======>.......................] - ETA: 656s - loss: 0.3451p276_044\n",
      "124/500 [======>.......................] - ETA: 654s - loss: 0.3453p273_239\n",
      "125/500 [======>.......................] - ETA: 652s - loss: 0.3446p269_058\n",
      "126/500 [======>.......................] - ETA: 650s - loss: 0.3448p277_195\n",
      "127/500 [======>.......................] - ETA: 648s - loss: 0.3442p269_091\n",
      "128/500 [======>.......................] - ETA: 646s - loss: 0.3423p286_093\n",
      "129/500 [======>.......................] - ETA: 644s - loss: 0.3451p254_313\n",
      "130/500 [======>.......................] - ETA: 643s - loss: 0.3467p243_333\n",
      "131/500 [======>.......................] - ETA: 641s - loss: 0.3472p236_199\n",
      "132/500 [======>.......................] - ETA: 639s - loss: 0.3475p276_231\n",
      "133/500 [======>.......................] - ETA: 637s - loss: 0.3461p258_291\n",
      "134/500 [=======>......................] - ETA: 635s - loss: 0.3479p286_108\n",
      "135/500 [=======>......................] - ETA: 633s - loss: 0.3480p244_271\n",
      "136/500 [=======>......................] - ETA: 631s - loss: 0.3524p227_131\n",
      "137/500 [=======>......................] - ETA: 629s - loss: 0.3518p239_364\n",
      "138/500 [=======>......................] - ETA: 627s - loss: 0.3513p268_212\n",
      "139/500 [=======>......................] - ETA: 625s - loss: 0.3534p269_364\n",
      "140/500 [=======>......................] - ETA: 624s - loss: 0.3537p228_102\n",
      "141/500 [=======>......................] - ETA: 622s - loss: 0.3521p286_333\n",
      "142/500 [=======>......................] - ETA: 620s - loss: 0.3506p270_020\n",
      "143/500 [=======>......................] - ETA: 618s - loss: 0.3503p279_364\n",
      "144/500 [=======>......................] - ETA: 616s - loss: 0.3487p250_154\n",
      "145/500 [=======>......................] - ETA: 614s - loss: 0.3479p274_436\n",
      "146/500 [=======>......................] - ETA: 612s - loss: 0.3471p258_276\n",
      "147/500 [=======>......................] - ETA: 611s - loss: 0.3459p231_263\n",
      "148/500 [=======>......................] - ETA: 609s - loss: 0.3445p273_039\n",
      "149/500 [=======>......................] - ETA: 607s - loss: 0.3445p259_217\n",
      "150/500 [========>.....................] - ETA: 605s - loss: 0.3499p256_265\n",
      "151/500 [========>.....................] - ETA: 603s - loss: 0.3495p243_308\n",
      "152/500 [========>.....................] - ETA: 601s - loss: 0.3483p239_014\n",
      "153/500 [========>.....................] - ETA: 599s - loss: 0.3491p244_059\n",
      "154/500 [========>.....................] - ETA: 598s - loss: 0.3489p233_064\n",
      "155/500 [========>.....................] - ETA: 596s - loss: 0.3482p277_281\n",
      "156/500 [========>.....................] - ETA: 594s - loss: 0.3476p250_192\n",
      "157/500 [========>.....................] - ETA: 592s - loss: 0.3461p239_219\n",
      "158/500 [========>.....................] - ETA: 591s - loss: 0.3453p233_319\n",
      "159/500 [========>.....................] - ETA: 589s - loss: 0.3450p279_292\n",
      "160/500 [========>.....................] - ETA: 587s - loss: 0.3449p268_138\n",
      "161/500 [========>.....................] - ETA: 585s - loss: 0.3444p243_341\n",
      "162/500 [========>.....................] - ETA: 583s - loss: 0.3434p233_132\n",
      "163/500 [========>.....................] - ETA: 582s - loss: 0.3430p276_103\n",
      "164/500 [========>.....................] - ETA: 580s - loss: 0.3430p233_177\n",
      "165/500 [========>.....................] - ETA: 578s - loss: 0.3433p282_344\n",
      "166/500 [========>.....................] - ETA: 576s - loss: 0.3423p243_073\n",
      "167/500 [=========>....................] - ETA: 574s - loss: 0.3409p243_135\n",
      "168/500 [=========>....................] - ETA: 572s - loss: 0.3401p269_386\n",
      "169/500 [=========>....................] - ETA: 570s - loss: 0.3398p239_089\n",
      "170/500 [=========>....................] - ETA: 569s - loss: 0.3385p258_080\n",
      "171/500 [=========>....................] - ETA: 567s - loss: 0.3373p231_071\n",
      "172/500 [=========>....................] - ETA: 565s - loss: 0.3364p269_386\n",
      "173/500 [=========>....................] - ETA: 563s - loss: 0.3379p239_005\n",
      "174/500 [=========>....................] - ETA: 561s - loss: 0.3377p278_304\n",
      "175/500 [=========>....................] - ETA: 559s - loss: 0.3376p286_107\n",
      "176/500 [=========>....................] - ETA: 558s - loss: 0.3372p231_296\n",
      "177/500 [=========>....................] - ETA: 556s - loss: 0.3363p256_114\n",
      "178/500 [=========>....................] - ETA: 554s - loss: 0.3357p286_236\n",
      "179/500 [=========>....................] - ETA: 552s - loss: 0.3363p259_354\n",
      "180/500 [=========>....................] - ETA: 550s - loss: 0.3358p278_094\n",
      "181/500 [=========>....................] - ETA: 548s - loss: 0.3345p226_293\n",
      "182/500 [=========>....................] - ETA: 546s - loss: 0.3341p278_168\n",
      "183/500 [=========>....................] - ETA: 545s - loss: 0.3349p259_310\n",
      "184/500 [==========>...................] - ETA: 543s - loss: 0.3341p286_252\n",
      "185/500 [==========>...................] - ETA: 541s - loss: 0.3339p244_329\n",
      "186/500 [==========>...................] - ETA: 539s - loss: 0.3343p230_288\n",
      "187/500 [==========>...................] - ETA: 537s - loss: 0.3342p267_336\n",
      "188/500 [==========>...................] - ETA: 536s - loss: 0.3331p267_057\n",
      "189/500 [==========>...................] - ETA: 534s - loss: 0.3325p270_459\n",
      "190/500 [==========>...................] - ETA: 532s - loss: 0.3320p268_050\n",
      "191/500 [==========>...................] - ETA: 530s - loss: 0.3312p254_007\n",
      "192/500 [==========>...................] - ETA: 528s - loss: 0.3300p230_104\n",
      "193/500 [==========>...................] - ETA: 527s - loss: 0.3288p277_056\n",
      "194/500 [==========>...................] - ETA: 525s - loss: 0.3277p239_290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/500 [==========>...................] - ETA: 523s - loss: 0.3274p250_325\n",
      "196/500 [==========>...................] - ETA: 521s - loss: 0.3269p273_052\n",
      "197/500 [==========>...................] - ETA: 520s - loss: 0.3264p226_295\n",
      "198/500 [==========>...................] - ETA: 518s - loss: 0.3280p233_260\n",
      "199/500 [==========>...................] - ETA: 516s - loss: 0.3274p250_009\n",
      "200/500 [===========>..................] - ETA: 514s - loss: 0.3296p277_377\n",
      "201/500 [===========>..................] - ETA: 513s - loss: 0.3295p259_380\n",
      "202/500 [===========>..................] - ETA: 511s - loss: 0.3291p256_026\n",
      "203/500 [===========>..................] - ETA: 509s - loss: 0.3286p256_319\n",
      "204/500 [===========>..................] - ETA: 507s - loss: 0.3281p258_223\n",
      "205/500 [===========>..................] - ETA: 506s - loss: 0.3273p273_245\n",
      "206/500 [===========>..................] - ETA: 504s - loss: 0.3281p270_227\n",
      "207/500 [===========>..................] - ETA: 502s - loss: 0.3280p278_204\n",
      "208/500 [===========>..................] - ETA: 500s - loss: 0.3282p269_244\n",
      "209/500 [===========>..................] - ETA: 499s - loss: 0.3276p236_178\n",
      "210/500 [===========>..................] - ETA: 497s - loss: 0.3272p236_340\n",
      "211/500 [===========>..................] - ETA: 495s - loss: 0.3268p270_029\n",
      "212/500 [===========>..................] - ETA: 493s - loss: 0.3265p277_333\n",
      "213/500 [===========>..................] - ETA: 491s - loss: 0.3257p226_143\n",
      "214/500 [===========>..................] - ETA: 490s - loss: 0.3253p276_433\n",
      "215/500 [===========>..................] - ETA: 488s - loss: 0.3246p244_069\n",
      "216/500 [===========>..................] - ETA: 486s - loss: 0.3249p267_359\n",
      "217/500 [============>.................] - ETA: 484s - loss: 0.3244p236_025\n",
      "218/500 [============>.................] - ETA: 483s - loss: 0.3239p268_205\n",
      "219/500 [============>.................] - ETA: 481s - loss: 0.3239p254_373\n",
      "220/500 [============>.................] - ETA: 479s - loss: 0.3234p287_156\n",
      "221/500 [============>.................] - ETA: 477s - loss: 0.3241p267_399\n",
      "222/500 [============>.................] - ETA: 476s - loss: 0.3240p244_083\n",
      "223/500 [============>.................] - ETA: 474s - loss: 0.3236p228_336\n",
      "224/500 [============>.................] - ETA: 472s - loss: 0.3227p287_342\n",
      "225/500 [============>.................] - ETA: 470s - loss: 0.3219p282_021\n",
      "226/500 [============>.................] - ETA: 468s - loss: 0.3229p256_104\n",
      "227/500 [============>.................] - ETA: 467s - loss: 0.3233p228_200\n",
      "228/500 [============>.................] - ETA: 465s - loss: 0.3225p254_386\n",
      "229/500 [============>.................] - ETA: 463s - loss: 0.3221p279_068\n",
      "230/500 [============>.................] - ETA: 461s - loss: 0.3216p286_075\n",
      "231/500 [============>.................] - ETA: 460s - loss: 0.3205p276_301\n",
      "232/500 [============>.................] - ETA: 458s - loss: 0.3200p279_402\n",
      "233/500 [============>.................] - ETA: 456s - loss: 0.3212p236_336\n",
      "234/500 [=============>................] - ETA: 454s - loss: 0.3214p239_339\n",
      "235/500 [=============>................] - ETA: 453s - loss: 0.3207p270_168\n",
      "236/500 [=============>................] - ETA: 451s - loss: 0.3201p274_450\n",
      "237/500 [=============>................] - ETA: 449s - loss: 0.3208p231_078\n",
      "238/500 [=============>................] - ETA: 447s - loss: 0.3206p278_333\n",
      "239/500 [=============>................] - ETA: 446s - loss: 0.3200p231_433\n",
      "240/500 [=============>................] - ETA: 444s - loss: 0.3190p273_087\n",
      "241/500 [=============>................] - ETA: 442s - loss: 0.3190p226_363\n",
      "242/500 [=============>................] - ETA: 440s - loss: 0.3183p231_299\n",
      "243/500 [=============>................] - ETA: 439s - loss: 0.3186p279_177\n",
      "244/500 [=============>................] - ETA: 437s - loss: 0.3180p231_231\n",
      "245/500 [=============>................] - ETA: 435s - loss: 0.3175p250_215\n",
      "246/500 [=============>................] - ETA: 433s - loss: 0.3172p227_191\n",
      "247/500 [=============>................] - ETA: 432s - loss: 0.3163p287_359\n",
      "248/500 [=============>................] - ETA: 430s - loss: 0.3157p256_292\n",
      "249/500 [=============>................] - ETA: 428s - loss: 0.3151p277_282\n",
      "250/500 [==============>...............] - ETA: 426s - loss: 0.3149p231_263\n",
      "251/500 [==============>...............] - ETA: 425s - loss: 0.3151p269_364\n",
      "252/500 [==============>...............] - ETA: 423s - loss: 0.3145p227_323\n",
      "253/500 [==============>...............] - ETA: 421s - loss: 0.3153p269_220\n",
      "254/500 [==============>...............] - ETA: 419s - loss: 0.3149p226_057\n",
      "255/500 [==============>...............] - ETA: 418s - loss: 0.3149p278_202\n",
      "256/500 [==============>...............] - ETA: 416s - loss: 0.3144p267_012\n",
      "257/500 [==============>...............] - ETA: 414s - loss: 0.3137p259_309\n",
      "258/500 [==============>...............] - ETA: 412s - loss: 0.3134p226_290\n",
      "259/500 [==============>...............] - ETA: 411s - loss: 0.3127p286_048\n",
      "260/500 [==============>...............] - ETA: 409s - loss: 0.3121p236_390\n",
      "261/500 [==============>...............] - ETA: 407s - loss: 0.3116p227_069\n",
      "262/500 [==============>...............] - ETA: 406s - loss: 0.3126p243_328\n",
      "263/500 [==============>...............] - ETA: 404s - loss: 0.3118p277_133\n",
      "264/500 [==============>...............] - ETA: 402s - loss: 0.3117p276_147\n",
      "265/500 [==============>...............] - ETA: 400s - loss: 0.3120p250_326\n",
      "266/500 [==============>...............] - ETA: 399s - loss: 0.3118p279_288\n",
      "267/500 [===============>..............] - ETA: 397s - loss: 0.3113p282_215\n",
      "268/500 [===============>..............] - ETA: 395s - loss: 0.3111p244_170\n",
      "269/500 [===============>..............] - ETA: 394s - loss: 0.3105p268_321\n",
      "270/500 [===============>..............] - ETA: 392s - loss: 0.3101p278_207\n",
      "271/500 [===============>..............] - ETA: 390s - loss: 0.3105p286_305\n",
      "272/500 [===============>..............] - ETA: 389s - loss: 0.3104p244_271\n",
      "273/500 [===============>..............] - ETA: 387s - loss: 0.3098p243_042\n",
      "274/500 [===============>..............] - ETA: 385s - loss: 0.3092p236_338\n",
      "275/500 [===============>..............] - ETA: 384s - loss: 0.3087p231_195\n",
      "276/500 [===============>..............] - ETA: 382s - loss: 0.3082p282_259\n",
      "277/500 [===============>..............] - ETA: 380s - loss: 0.3074p282_194\n",
      "278/500 [===============>..............] - ETA: 379s - loss: 0.3068p258_322\n",
      "279/500 [===============>..............] - ETA: 377s - loss: 0.3070p278_062\n",
      "280/500 [===============>..............] - ETA: 375s - loss: 0.3068p250_309\n",
      "281/500 [===============>..............] - ETA: 374s - loss: 0.3063p267_322\n",
      "282/500 [===============>..............] - ETA: 372s - loss: 0.3060p236_411\n",
      "283/500 [===============>..............] - ETA: 370s - loss: 0.3055p230_279\n",
      "284/500 [================>.............] - ETA: 368s - loss: 0.3049p274_108\n",
      "285/500 [================>.............] - ETA: 367s - loss: 0.3049p243_395\n",
      "286/500 [================>.............] - ETA: 365s - loss: 0.3046p243_095\n",
      "287/500 [================>.............] - ETA: 363s - loss: 0.3038p274_276\n",
      "288/500 [================>.............] - ETA: 362s - loss: 0.3040p243_314\n",
      "289/500 [================>.............] - ETA: 360s - loss: 0.3035p282_299\n",
      "290/500 [================>.............] - ETA: 358s - loss: 0.3032p244_054\n",
      "291/500 [================>.............] - ETA: 356s - loss: 0.3028p279_161\n",
      "292/500 [================>.............] - ETA: 355s - loss: 0.3025p273_212\n",
      "293/500 [================>.............] - ETA: 353s - loss: 0.3023p277_064\n",
      "294/500 [================>.............] - ETA: 351s - loss: 0.3020p227_267\n",
      "295/500 [================>.............] - ETA: 350s - loss: 0.3018p228_303\n",
      "296/500 [================>.............] - ETA: 348s - loss: 0.3010p231_401\n",
      "297/500 [================>.............] - ETA: 346s - loss: 0.3006p228_102\n",
      "298/500 [================>.............] - ETA: 344s - loss: 0.3000p254_129\n",
      "299/500 [================>.............] - ETA: 343s - loss: 0.2998p239_006\n",
      "300/500 [=================>............] - ETA: 341s - loss: 0.2992p259_256\n",
      "301/500 [=================>............] - ETA: 339s - loss: 0.2993p278_047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/500 [=================>............] - ETA: 337s - loss: 0.2986p287_106\n",
      "303/500 [=================>............] - ETA: 336s - loss: 0.2993p274_171\n",
      "304/500 [=================>............] - ETA: 334s - loss: 0.2986p259_295\n",
      "305/500 [=================>............] - ETA: 332s - loss: 0.2982p228_280\n",
      "306/500 [=================>............] - ETA: 331s - loss: 0.2984p268_184\n",
      "307/500 [=================>............] - ETA: 329s - loss: 0.2983p274_306\n",
      "308/500 [=================>............] - ETA: 327s - loss: 0.2984p273_170\n",
      "309/500 [=================>............] - ETA: 325s - loss: 0.2989p259_336\n",
      "310/500 [=================>............] - ETA: 324s - loss: 0.2988p254_365\n",
      "311/500 [=================>............] - ETA: 322s - loss: 0.2983p227_172\n",
      "312/500 [=================>............] - ETA: 320s - loss: 0.2977p258_378\n",
      "313/500 [=================>............] - ETA: 319s - loss: 0.2976p274_335\n",
      "314/500 [=================>............] - ETA: 317s - loss: 0.2970p279_031\n",
      "315/500 [=================>............] - ETA: 315s - loss: 0.2965p267_014\n",
      "316/500 [=================>............] - ETA: 313s - loss: 0.2974p273_126\n",
      "317/500 [==================>...........] - ETA: 312s - loss: 0.2971p228_030\n",
      "318/500 [==================>...........] - ETA: 310s - loss: 0.2968p277_053\n",
      "319/500 [==================>...........] - ETA: 308s - loss: 0.2965p273_124\n",
      "320/500 [==================>...........] - ETA: 307s - loss: 0.2960p286_353\n",
      "321/500 [==================>...........] - ETA: 305s - loss: 0.2960p269_333\n",
      "322/500 [==================>...........] - ETA: 303s - loss: 0.2955p277_406\n",
      "323/500 [==================>...........] - ETA: 301s - loss: 0.2948p258_363\n",
      "324/500 [==================>...........] - ETA: 300s - loss: 0.2944p231_275\n",
      "325/500 [==================>...........] - ETA: 298s - loss: 0.2943p243_054\n",
      "326/500 [==================>...........] - ETA: 296s - loss: 0.2945p243_272\n",
      "327/500 [==================>...........] - ETA: 295s - loss: 0.2957p236_165\n",
      "328/500 [==================>...........] - ETA: 293s - loss: 0.2956p250_488\n",
      "329/500 [==================>...........] - ETA: 291s - loss: 0.2952p250_360\n",
      "330/500 [==================>...........] - ETA: 289s - loss: 0.2952p273_135\n",
      "331/500 [==================>...........] - ETA: 288s - loss: 0.2947p267_387\n",
      "332/500 [==================>...........] - ETA: 286s - loss: 0.2953p269_081\n",
      "333/500 [==================>...........] - ETA: 284s - loss: 0.2954p244_390\n",
      "334/500 [===================>..........] - ETA: 283s - loss: 0.2949p269_068\n",
      "335/500 [===================>..........] - ETA: 281s - loss: 0.2945p274_217\n",
      "336/500 [===================>..........] - ETA: 279s - loss: 0.2939p282_365\n",
      "337/500 [===================>..........] - ETA: 277s - loss: 0.2933p258_067\n",
      "338/500 [===================>..........] - ETA: 276s - loss: 0.2931p268_108\n",
      "339/500 [===================>..........] - ETA: 274s - loss: 0.2941p269_309\n",
      "340/500 [===================>..........] - ETA: 272s - loss: 0.2947p243_341\n",
      "341/500 [===================>..........] - ETA: 271s - loss: 0.2951p243_054\n",
      "342/500 [===================>..........] - ETA: 269s - loss: 0.2949p244_022\n",
      "343/500 [===================>..........] - ETA: 267s - loss: 0.2956p259_340\n",
      "344/500 [===================>..........] - ETA: 265s - loss: 0.2962p227_236\n",
      "345/500 [===================>..........] - ETA: 264s - loss: 0.2971p231_210\n",
      "346/500 [===================>..........] - ETA: 262s - loss: 0.2965p277_353\n",
      "347/500 [===================>..........] - ETA: 260s - loss: 0.2961p226_230\n",
      "348/500 [===================>..........] - ETA: 259s - loss: 0.2955p239_222\n",
      "349/500 [===================>..........] - ETA: 257s - loss: 0.2958p259_056\n",
      "350/500 [====================>.........] - ETA: 255s - loss: 0.2962p282_276\n",
      "351/500 [====================>.........] - ETA: 253s - loss: 0.2959p270_175\n",
      "352/500 [====================>.........] - ETA: 252s - loss: 0.2956p273_086\n",
      "353/500 [====================>.........] - ETA: 250s - loss: 0.2953p231_073\n",
      "354/500 [====================>.........] - ETA: 248s - loss: 0.2951p276_253\n",
      "355/500 [====================>.........] - ETA: 247s - loss: 0.2946p274_169\n",
      "356/500 [====================>.........] - ETA: 245s - loss: 0.2942p259_155\n",
      "357/500 [====================>.........] - ETA: 243s - loss: 0.2939p279_174\n",
      "358/500 [====================>.........] - ETA: 241s - loss: 0.2936p233_320\n",
      "359/500 [====================>.........] - ETA: 240s - loss: 0.2936p279_058\n",
      "360/500 [====================>.........] - ETA: 238s - loss: 0.2931p228_233\n",
      "361/500 [====================>.........] - ETA: 236s - loss: 0.2926p277_365\n",
      "362/500 [====================>.........] - ETA: 235s - loss: 0.2933p230_096\n",
      "363/500 [====================>.........] - ETA: 233s - loss: 0.2932p243_287\n",
      "364/500 [====================>.........] - ETA: 231s - loss: 0.2926p276_207\n",
      "365/500 [====================>.........] - ETA: 229s - loss: 0.2927p276_241\n",
      "366/500 [====================>.........] - ETA: 228s - loss: 0.2921p273_199\n",
      "367/500 [=====================>........] - ETA: 226s - loss: 0.2916p230_190\n",
      "368/500 [=====================>........] - ETA: 224s - loss: 0.2914p230_407\n",
      "369/500 [=====================>........] - ETA: 223s - loss: 0.2911p231_237\n",
      "370/500 [=====================>........] - ETA: 221s - loss: 0.2910p236_130\n",
      "371/500 [=====================>........] - ETA: 219s - loss: 0.2908p233_107\n",
      "372/500 [=====================>........] - ETA: 217s - loss: 0.2902p258_215\n",
      "373/500 [=====================>........] - ETA: 216s - loss: 0.2900p267_414\n",
      "374/500 [=====================>........] - ETA: 214s - loss: 0.2895p227_003\n",
      "375/500 [=====================>........] - ETA: 212s - loss: 0.2901p268_303\n",
      "376/500 [=====================>........] - ETA: 211s - loss: 0.2899p250_191\n",
      "377/500 [=====================>........] - ETA: 209s - loss: 0.2906p279_361\n",
      "378/500 [=====================>........] - ETA: 207s - loss: 0.2904p269_037\n",
      "379/500 [=====================>........] - ETA: 206s - loss: 0.2901p244_401\n",
      "380/500 [=====================>........] - ETA: 204s - loss: 0.2896p226_213\n",
      "381/500 [=====================>........] - ETA: 202s - loss: 0.2893p259_200\n",
      "382/500 [=====================>........] - ETA: 200s - loss: 0.2897p236_283\n",
      "383/500 [=====================>........] - ETA: 199s - loss: 0.2892p286_468\n",
      "384/500 [======================>.......] - ETA: 197s - loss: 0.2891p233_174\n",
      "385/500 [======================>.......] - ETA: 195s - loss: 0.2884p270_432\n",
      "386/500 [======================>.......] - ETA: 194s - loss: 0.2881p276_272\n",
      "387/500 [======================>.......] - ETA: 192s - loss: 0.2877p267_330\n",
      "388/500 [======================>.......] - ETA: 190s - loss: 0.2878p277_186\n",
      "389/500 [======================>.......] - ETA: 188s - loss: 0.2877p258_153\n",
      "390/500 [======================>.......] - ETA: 187s - loss: 0.2879p243_322\n",
      "391/500 [======================>.......] - ETA: 185s - loss: 0.2886p259_207\n",
      "392/500 [======================>.......] - ETA: 183s - loss: 0.2884p233_027\n",
      "393/500 [======================>.......] - ETA: 182s - loss: 0.2883p250_141\n",
      "394/500 [======================>.......] - ETA: 180s - loss: 0.2878p243_145\n",
      "395/500 [======================>.......] - ETA: 178s - loss: 0.2873p273_039\n",
      "396/500 [======================>.......] - ETA: 177s - loss: 0.2870p270_258\n",
      "397/500 [======================>.......] - ETA: 175s - loss: 0.2882p258_297\n",
      "398/500 [======================>.......] - ETA: 173s - loss: 0.2881p227_022\n",
      "399/500 [======================>.......] - ETA: 171s - loss: 0.2877p228_129\n",
      "400/500 [=======================>......] - ETA: 170s - loss: 0.2872p278_086\n",
      "401/500 [=======================>......] - ETA: 168s - loss: 0.2868p276_370\n",
      "402/500 [=======================>......] - ETA: 166s - loss: 0.2865p236_389\n",
      "403/500 [=======================>......] - ETA: 165s - loss: 0.2863p230_055\n",
      "404/500 [=======================>......] - ETA: 163s - loss: 0.2859p230_295\n",
      "405/500 [=======================>......] - ETA: 161s - loss: 0.2853p277_119\n",
      "406/500 [=======================>......] - ETA: 159s - loss: 0.2853p244_108\n",
      "407/500 [=======================>......] - ETA: 158s - loss: 0.2854p269_020\n",
      "408/500 [=======================>......] - ETA: 156s - loss: 0.2849p254_239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/500 [=======================>......] - ETA: 154s - loss: 0.2843p244_270\n",
      "410/500 [=======================>......] - ETA: 153s - loss: 0.2847p250_192\n",
      "411/500 [=======================>......] - ETA: 151s - loss: 0.2845p236_227\n",
      "412/500 [=======================>......] - ETA: 149s - loss: 0.2848p270_084\n",
      "413/500 [=======================>......] - ETA: 148s - loss: 0.2845p267_189\n",
      "414/500 [=======================>......] - ETA: 146s - loss: 0.2844p274_391\n",
      "415/500 [=======================>......] - ETA: 144s - loss: 0.2839p233_004\n",
      "416/500 [=======================>......] - ETA: 142s - loss: 0.2835p276_336\n",
      "417/500 [========================>.....] - ETA: 141s - loss: 0.2838p244_189\n",
      "418/500 [========================>.....] - ETA: 139s - loss: 0.2840p287_320\n",
      "419/500 [========================>.....] - ETA: 137s - loss: 0.2836p273_234\n",
      "420/500 [========================>.....] - ETA: 136s - loss: 0.2834p270_307\n",
      "421/500 [========================>.....] - ETA: 134s - loss: 0.2831p276_232\n",
      "422/500 [========================>.....] - ETA: 132s - loss: 0.2828p231_090\n",
      "423/500 [========================>.....] - ETA: 130s - loss: 0.2832p243_002\n",
      "424/500 [========================>.....] - ETA: 129s - loss: 0.2833p233_229\n",
      "425/500 [========================>.....] - ETA: 127s - loss: 0.2828p244_260\n",
      "426/500 [========================>.....] - ETA: 125s - loss: 0.2831p274_208\n",
      "427/500 [========================>.....] - ETA: 124s - loss: 0.2831p243_035\n",
      "428/500 [========================>.....] - ETA: 122s - loss: 0.2834p276_352\n",
      "429/500 [========================>.....] - ETA: 120s - loss: 0.2832p279_348\n",
      "430/500 [========================>.....] - ETA: 119s - loss: 0.2828p256_088\n",
      "431/500 [========================>.....] - ETA: 117s - loss: 0.2829p270_197\n",
      "432/500 [========================>.....] - ETA: 115s - loss: 0.2830p273_138\n",
      "433/500 [========================>.....] - ETA: 113s - loss: 0.2826p278_138\n",
      "434/500 [=========================>....] - ETA: 112s - loss: 0.2821p226_357\n",
      "435/500 [=========================>....] - ETA: 110s - loss: 0.2818p269_227\n",
      "436/500 [=========================>....] - ETA: 108s - loss: 0.2817p227_279\n",
      "437/500 [=========================>....] - ETA: 107s - loss: 0.2813p258_405\n",
      "438/500 [=========================>....] - ETA: 105s - loss: 0.2808p268_232\n",
      "439/500 [=========================>....] - ETA: 103s - loss: 0.2805p286_279\n",
      "440/500 [=========================>....] - ETA: 102s - loss: 0.2802p227_261\n",
      "441/500 [=========================>....] - ETA: 100s - loss: 0.2803p226_066\n",
      "442/500 [=========================>....] - ETA: 98s - loss: 0.2801 p279_194\n",
      "443/500 [=========================>....] - ETA: 96s - loss: 0.2802p269_374\n",
      "444/500 [=========================>....] - ETA: 95s - loss: 0.2797p227_256\n",
      "445/500 [=========================>....] - ETA: 93s - loss: 0.2796p282_301\n",
      "446/500 [=========================>....] - ETA: 91s - loss: 0.2797p243_345\n",
      "447/500 [=========================>....] - ETA: 90s - loss: 0.2793p268_052\n",
      "448/500 [=========================>....] - ETA: 88s - loss: 0.2791p244_172\n",
      "449/500 [=========================>....] - ETA: 86s - loss: 0.2790p286_238\n",
      "450/500 [==========================>...] - ETA: 85s - loss: 0.2787p276_038\n",
      "451/500 [==========================>...] - ETA: 83s - loss: 0.2782p236_370\n",
      "452/500 [==========================>...] - ETA: 81s - loss: 0.2779p287_230\n",
      "453/500 [==========================>...] - ETA: 79s - loss: 0.2776p236_167\n",
      "454/500 [==========================>...] - ETA: 78s - loss: 0.2780p278_145\n",
      "455/500 [==========================>...] - ETA: 76s - loss: 0.2776p277_047\n",
      "456/500 [==========================>...] - ETA: 74s - loss: 0.2772p270_095\n",
      "457/500 [==========================>...] - ETA: 73s - loss: 0.2767p226_351\n",
      "458/500 [==========================>...] - ETA: 71s - loss: 0.2766p258_411\n",
      "459/500 [==========================>...] - ETA: 69s - loss: 0.2768p258_114\n",
      "460/500 [==========================>...] - ETA: 67s - loss: 0.2764p243_309\n",
      "461/500 [==========================>...] - ETA: 66s - loss: 0.2764p259_055\n",
      "462/500 [==========================>...] - ETA: 64s - loss: 0.2761p239_027\n",
      "463/500 [==========================>...] - ETA: 62s - loss: 0.2759p256_006\n",
      "464/500 [==========================>...] - ETA: 61s - loss: 0.2757p276_123\n",
      "465/500 [==========================>...] - ETA: 59s - loss: 0.2752p277_463\n",
      "466/500 [==========================>...] - ETA: 57s - loss: 0.2751p258_017\n",
      "467/500 [===========================>..] - ETA: 56s - loss: 0.2752p226_181\n",
      "468/500 [===========================>..] - ETA: 54s - loss: 0.2748p267_070\n",
      "469/500 [===========================>..] - ETA: 52s - loss: 0.2745p273_021\n",
      "470/500 [===========================>..] - ETA: 50s - loss: 0.2742p227_011\n",
      "471/500 [===========================>..] - ETA: 49s - loss: 0.2737p244_097\n",
      "472/500 [===========================>..] - ETA: 47s - loss: 0.2733p282_279\n",
      "473/500 [===========================>..] - ETA: 45s - loss: 0.2730p233_274\n",
      "474/500 [===========================>..] - ETA: 44s - loss: 0.2726p227_307\n",
      "475/500 [===========================>..] - ETA: 42s - loss: 0.2726p230_140\n",
      "476/500 [===========================>..] - ETA: 40s - loss: 0.2723p233_291\n",
      "477/500 [===========================>..] - ETA: 39s - loss: 0.2720p286_327\n",
      "478/500 [===========================>..] - ETA: 37s - loss: 0.2719p239_044\n",
      "479/500 [===========================>..] - ETA: 35s - loss: 0.2718p236_262\n",
      "480/500 [===========================>..] - ETA: 33s - loss: 0.2717p254_343\n",
      "481/500 [===========================>..] - ETA: 32s - loss: 0.2716p274_196\n",
      "482/500 [===========================>..] - ETA: 30s - loss: 0.2722p256_146\n",
      "483/500 [===========================>..] - ETA: 28s - loss: 0.2724p287_404\n",
      "484/500 [============================>.] - ETA: 27s - loss: 0.2728p279_018\n",
      "485/500 [============================>.] - ETA: 25s - loss: 0.2724p236_342\n",
      "486/500 [============================>.] - ETA: 23s - loss: 0.2724p269_229\n",
      "487/500 [============================>.] - ETA: 22s - loss: 0.2724p233_026\n",
      "488/500 [============================>.] - ETA: 20s - loss: 0.2722p278_207\n",
      "489/500 [============================>.] - ETA: 18s - loss: 0.2724p278_023\n",
      "490/500 [============================>.] - ETA: 16s - loss: 0.2725p273_136\n",
      "491/500 [============================>.] - ETA: 15s - loss: 0.2731p233_086\n",
      "492/500 [============================>.] - ETA: 13s - loss: 0.2730p226_287\n",
      "493/500 [============================>.] - ETA: 11s - loss: 0.2729p259_396\n",
      "494/500 [============================>.] - ETA: 10s - loss: 0.2729p250_488\n",
      "495/500 [============================>.] - ETA: 8s - loss: 0.2727 p273_264\n",
      "496/500 [============================>.] - ETA: 6s - loss: 0.2725p273_431\n",
      "497/500 [============================>.] - ETA: 5s - loss: 0.2724p282_190\n",
      "498/500 [============================>.] - ETA: 3s - loss: 0.2722p228_342\n",
      "499/500 [============================>.] - ETA: 1s - loss: 0.2720p268_215\n",
      "Epoch 00000: loss improved from inf to 0.27168, saving model to v6__CNNBiRNN_deeper/Checkpoint_Model_Weights/v6_1/weights_v6_1_Epoch-0000_L-0.27.hdf5\n",
      "500/500 [==============================] - 849s - loss: 0.2717   \n",
      "Epoch 2/100\n",
      "p259_306\n",
      "  1/500 [..............................] - ETA: 831s - loss: 0.0788p233_338\n",
      "  2/500 [..............................] - ETA: 832s - loss: 0.1628p233_071\n",
      "  3/500 [..............................] - ETA: 832s - loss: 0.4289p273_331\n",
      "  4/500 [..............................] - ETA: 831s - loss: 0.3544p267_127\n",
      "  5/500 [..............................] - ETA: 830s - loss: 0.3742p268_328\n",
      "  6/500 [..............................] - ETA: 830s - loss: 0.3303p258_042\n",
      "  7/500 [..............................] - ETA: 829s - loss: 0.3168p243_368\n",
      "  8/500 [..............................] - ETA: 827s - loss: 0.3137p239_344\n",
      "  9/500 [..............................] - ETA: 826s - loss: 0.3043p270_336\n",
      " 10/500 [..............................] - ETA: 826s - loss: 0.3014p230_182\n",
      " 11/500 [..............................] - ETA: 827s - loss: 0.2936p233_044\n",
      " 12/500 [..............................] - ETA: 828s - loss: 0.2954p244_398\n",
      " 13/500 [..............................] - ETA: 826s - loss: 0.2862p269_154\n",
      " 14/500 [..............................] - ETA: 824s - loss: 0.2796p239_305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/500 [..............................] - ETA: 822s - loss: 0.2667p236_081\n",
      " 16/500 [..............................] - ETA: 821s - loss: 0.2609p227_059\n",
      " 17/500 [>.............................] - ETA: 819s - loss: 0.2521p268_143\n",
      " 18/500 [>.............................] - ETA: 817s - loss: 0.2477p274_266\n",
      " 19/500 [>.............................] - ETA: 815s - loss: 0.2396p270_176\n",
      " 20/500 [>.............................] - ETA: 813s - loss: 0.2466p269_117\n",
      " 21/500 [>.............................] - ETA: 810s - loss: 0.2415p250_090\n",
      " 22/500 [>.............................] - ETA: 808s - loss: 0.2366p228_060\n",
      " 23/500 [>.............................] - ETA: 806s - loss: 0.2327p230_031\n",
      " 24/500 [>.............................] - ETA: 805s - loss: 0.2281p239_422\n",
      " 25/500 [>.............................] - ETA: 802s - loss: 0.2242p276_132\n",
      " 26/500 [>.............................] - ETA: 801s - loss: 0.2287p274_100\n",
      " 27/500 [>.............................] - ETA: 799s - loss: 0.2226p236_398\n",
      " 28/500 [>.............................] - ETA: 798s - loss: 0.2239p268_371\n",
      " 29/500 [>.............................] - ETA: 796s - loss: 0.2197p286_437\n",
      " 30/500 [>.............................] - ETA: 794s - loss: 0.2222p286_397\n",
      " 31/500 [>.............................] - ETA: 793s - loss: 0.2227p231_142\n",
      " 32/500 [>.............................] - ETA: 791s - loss: 0.2263p274_211\n",
      " 33/500 [>.............................] - ETA: 789s - loss: 0.2254p269_056\n",
      " 34/500 [=>............................] - ETA: 787s - loss: 0.2217p244_207\n",
      " 35/500 [=>............................] - ETA: 785s - loss: 0.2186p258_068\n",
      " 36/500 [=>............................] - ETA: 783s - loss: 0.2251p239_062\n",
      " 37/500 [=>............................] - ETA: 781s - loss: 0.2227p287_198\n",
      " 38/500 [=>............................] - ETA: 779s - loss: 0.2254p273_355\n",
      " 39/500 [=>............................] - ETA: 779s - loss: 0.2235p276_377\n",
      " 40/500 [=>............................] - ETA: 777s - loss: 0.2218p276_107\n",
      " 41/500 [=>............................] - ETA: 776s - loss: 0.2203p278_086\n",
      " 42/500 [=>............................] - ETA: 774s - loss: 0.2174p278_335\n",
      " 43/500 [=>............................] - ETA: 772s - loss: 0.2146p250_225\n",
      " 44/500 [=>............................] - ETA: 770s - loss: 0.2143p259_417\n",
      " 45/500 [=>............................] - ETA: 768s - loss: 0.2126p254_183\n",
      " 46/500 [=>............................] - ETA: 766s - loss: 0.2159p286_425\n",
      " 47/500 [=>............................] - ETA: 764s - loss: 0.2144p279_170\n",
      " 48/500 [=>............................] - ETA: 763s - loss: 0.2143p254_318\n",
      " 49/500 [=>............................] - ETA: 761s - loss: 0.2129p279_240\n",
      " 50/500 [==>...........................] - ETA: 760s - loss: 0.2127p244_409\n",
      " 51/500 [==>...........................] - ETA: 758s - loss: 0.2110p244_100\n",
      " 52/500 [==>...........................] - ETA: 756s - loss: 0.2113p269_144\n",
      " 53/500 [==>...........................] - ETA: 755s - loss: 0.2090p254_196\n",
      " 54/500 [==>...........................] - ETA: 753s - loss: 0.2071p268_317\n",
      " 55/500 [==>...........................] - ETA: 751s - loss: 0.2062p277_231\n",
      " 56/500 [==>...........................] - ETA: 750s - loss: 0.2045p226_190\n",
      " 57/500 [==>...........................] - ETA: 748s - loss: 0.2027p282_360\n",
      " 58/500 [==>...........................] - ETA: 746s - loss: 0.2006p233_228\n",
      " 59/500 [==>...........................] - ETA: 744s - loss: 0.1986p279_184\n",
      " 60/500 [==>...........................] - ETA: 742s - loss: 0.1983p254_365\n",
      " 61/500 [==>...........................] - ETA: 740s - loss: 0.1995p270_347\n",
      " 62/500 [==>...........................] - ETA: 739s - loss: 0.2022p278_198\n",
      " 63/500 [==>...........................] - ETA: 737s - loss: 0.2016p273_334\n",
      " 64/500 [==>...........................] - ETA: 735s - loss: 0.2010p256_084\n",
      " 65/500 [==>...........................] - ETA: 734s - loss: 0.2002p282_245\n",
      " 66/500 [==>...........................] - ETA: 732s - loss: 0.1996p259_458\n",
      " 67/500 [===>..........................] - ETA: 730s - loss: 0.1979p286_416\n",
      " 68/500 [===>..........................] - ETA: 728s - loss: 0.1973p227_099\n",
      " 69/500 [===>..........................] - ETA: 727s - loss: 0.1980p274_469\n",
      " 70/500 [===>..........................] - ETA: 725s - loss: 0.1983p231_017\n",
      " 71/500 [===>..........................] - ETA: 723s - loss: 0.1982p287_212\n",
      " 72/500 [===>..........................] - ETA: 721s - loss: 0.1993p277_199\n",
      " 73/500 [===>..........................] - ETA: 720s - loss: 0.1976p273_405\n",
      " 74/500 [===>..........................] - ETA: 718s - loss: 0.1960p268_038\n",
      " 75/500 [===>..........................] - ETA: 716s - loss: 0.1967p243_140\n",
      " 76/500 [===>..........................] - ETA: 715s - loss: 0.1959p244_263\n",
      " 77/500 [===>..........................] - ETA: 713s - loss: 0.1941p233_019\n",
      " 78/500 [===>..........................] - ETA: 711s - loss: 0.1954p233_151\n",
      " 79/500 [===>..........................] - ETA: 710s - loss: 0.1939p287_383\n",
      " 80/500 [===>..........................] - ETA: 708s - loss: 0.1928p230_145\n",
      " 81/500 [===>..........................] - ETA: 706s - loss: 0.1931p279_140\n",
      " 82/500 [===>..........................] - ETA: 705s - loss: 0.1931p286_128\n",
      " 83/500 [===>..........................] - ETA: 703s - loss: 0.1919p231_407\n",
      " 84/500 [====>.........................] - ETA: 701s - loss: 0.1922p227_192\n",
      " 85/500 [====>.........................] - ETA: 699s - loss: 0.1934p279_262\n",
      " 86/500 [====>.........................] - ETA: 697s - loss: 0.1924p250_496\n",
      " 87/500 [====>.........................] - ETA: 696s - loss: 0.1922p230_125\n",
      " 88/500 [====>.........................] - ETA: 694s - loss: 0.1909p228_359\n",
      " 89/500 [====>.........................] - ETA: 692s - loss: 0.1911p244_221\n",
      " 90/500 [====>.........................] - ETA: 691s - loss: 0.1899p244_252\n",
      " 91/500 [====>.........................] - ETA: 689s - loss: 0.1890p256_074\n",
      " 92/500 [====>.........................] - ETA: 688s - loss: 0.1879p254_395\n",
      " 93/500 [====>.........................] - ETA: 686s - loss: 0.1873p239_170\n",
      " 94/500 [====>.........................] - ETA: 684s - loss: 0.1863p233_130\n",
      " 95/500 [====>.........................] - ETA: 682s - loss: 0.1859p236_294\n",
      " 96/500 [====>.........................] - ETA: 681s - loss: 0.1854p236_097\n",
      " 97/500 [====>.........................] - ETA: 679s - loss: 0.1842p231_385\n",
      " 98/500 [====>.........................] - ETA: 677s - loss: 0.1832p233_018\n",
      " 99/500 [====>.........................] - ETA: 675s - loss: 0.1819p226_004\n",
      "100/500 [=====>........................] - ETA: 674s - loss: 0.1816p267_055\n",
      "101/500 [=====>........................] - ETA: 672s - loss: 0.1831p282_294\n",
      "102/500 [=====>........................] - ETA: 670s - loss: 0.1821p228_049\n",
      "103/500 [=====>........................] - ETA: 668s - loss: 0.1808p228_085\n",
      "104/500 [=====>........................] - ETA: 667s - loss: 0.1801p267_301\n",
      "105/500 [=====>........................] - ETA: 665s - loss: 0.1797p282_206\n",
      "106/500 [=====>........................] - ETA: 663s - loss: 0.1784p258_386\n",
      "107/500 [=====>........................] - ETA: 662s - loss: 0.1791p269_332\n",
      "108/500 [=====>........................] - ETA: 660s - loss: 0.1790p282_201\n",
      "109/500 [=====>........................] - ETA: 658s - loss: 0.1782p236_161\n",
      "110/500 [=====>........................] - ETA: 656s - loss: 0.1779p258_205\n",
      "111/500 [=====>........................] - ETA: 655s - loss: 0.1784p274_447\n",
      "112/500 [=====>........................] - ETA: 653s - loss: 0.1773p236_319\n",
      "113/500 [=====>........................] - ETA: 651s - loss: 0.1789p267_061\n",
      "114/500 [=====>........................] - ETA: 649s - loss: 0.1786p274_042\n",
      "115/500 [=====>........................] - ETA: 648s - loss: 0.1785p267_196\n",
      "116/500 [=====>........................] - ETA: 646s - loss: 0.1780p267_345\n",
      "117/500 [======>.......................] - ETA: 644s - loss: 0.1777p250_120\n",
      "118/500 [======>.......................] - ETA: 642s - loss: 0.1776p227_262\n",
      "119/500 [======>.......................] - ETA: 641s - loss: 0.1776p278_226\n",
      "120/500 [======>.......................] - ETA: 639s - loss: 0.1775p259_445\n",
      "121/500 [======>.......................] - ETA: 637s - loss: 0.1770p243_003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/500 [======>.......................] - ETA: 636s - loss: 0.1760p236_212\n",
      "123/500 [======>.......................] - ETA: 634s - loss: 0.1761p227_119\n",
      "124/500 [======>.......................] - ETA: 632s - loss: 0.1790p236_232\n",
      "125/500 [======>.......................] - ETA: 630s - loss: 0.1783p276_274\n",
      "126/500 [======>.......................] - ETA: 629s - loss: 0.1784p274_354\n",
      "127/500 [======>.......................] - ETA: 627s - loss: 0.1785p287_373\n",
      "128/500 [======>.......................] - ETA: 626s - loss: 0.1778p282_027\n",
      "129/500 [======>.......................] - ETA: 624s - loss: 0.1777p258_034\n",
      "130/500 [======>.......................] - ETA: 622s - loss: 0.1773p227_186\n",
      "131/500 [======>.......................] - ETA: 621s - loss: 0.1768p287_152\n",
      "132/500 [======>.......................] - ETA: 619s - loss: 0.1760p278_021\n",
      "133/500 [======>.......................] - ETA: 617s - loss: 0.1754p278_373\n",
      "134/500 [=======>......................] - ETA: 616s - loss: 0.1744p259_315\n",
      "135/500 [=======>......................] - ETA: 614s - loss: 0.1747p231_398\n",
      "136/500 [=======>......................] - ETA: 612s - loss: 0.1774p227_241\n",
      "137/500 [=======>......................] - ETA: 611s - loss: 0.1766p270_123\n",
      "138/500 [=======>......................] - ETA: 609s - loss: 0.1760p259_001\n",
      "139/500 [=======>......................] - ETA: 607s - loss: 0.1755p267_421\n",
      "140/500 [=======>......................] - ETA: 606s - loss: 0.1748p231_128\n",
      "141/500 [=======>......................] - ETA: 604s - loss: 0.1739p228_335\n",
      "142/500 [=======>......................] - ETA: 602s - loss: 0.1749p236_414\n",
      "143/500 [=======>......................] - ETA: 601s - loss: 0.1746p259_307\n",
      "144/500 [=======>......................] - ETA: 599s - loss: 0.1749p267_143\n",
      "145/500 [=======>......................] - ETA: 597s - loss: 0.1747p236_047\n",
      "146/500 [=======>......................] - ETA: 596s - loss: 0.1742p230_148\n",
      "147/500 [=======>......................] - ETA: 594s - loss: 0.1735p268_120\n",
      "148/500 [=======>......................] - ETA: 592s - loss: 0.1744p233_215\n",
      "149/500 [=======>......................] - ETA: 591s - loss: 0.1744p273_238\n",
      "150/500 [========>.....................] - ETA: 589s - loss: 0.1746p278_046\n",
      "151/500 [========>.....................] - ETA: 587s - loss: 0.1744p226_260\n",
      "152/500 [========>.....................] - ETA: 585s - loss: 0.1740p250_336\n",
      "153/500 [========>.....................] - ETA: 584s - loss: 0.1739p277_246\n",
      "154/500 [========>.....................] - ETA: 582s - loss: 0.1731p231_359\n",
      "155/500 [========>.....................] - ETA: 580s - loss: 0.1735p236_407\n",
      "156/500 [========>.....................] - ETA: 579s - loss: 0.1732p236_473\n",
      "157/500 [========>.....................] - ETA: 577s - loss: 0.1725p228_020\n",
      "158/500 [========>.....................] - ETA: 575s - loss: 0.1733p267_239\n",
      "159/500 [========>.....................] - ETA: 574s - loss: 0.1734p259_327\n",
      "160/500 [========>.....................] - ETA: 572s - loss: 0.1739p267_254\n",
      "161/500 [========>.....................] - ETA: 571s - loss: 0.1734p277_296\n",
      "162/500 [========>.....................] - ETA: 569s - loss: 0.1731p268_405\n",
      "163/500 [========>.....................] - ETA: 567s - loss: 0.1730p230_115\n",
      "164/500 [========>.....................] - ETA: 565s - loss: 0.1725p286_425\n",
      "165/500 [========>.....................] - ETA: 564s - loss: 0.1725p279_141\n",
      "166/500 [========>.....................] - ETA: 562s - loss: 0.1721p227_062\n",
      "167/500 [=========>....................] - ETA: 560s - loss: 0.1719p278_179\n",
      "168/500 [=========>....................] - ETA: 559s - loss: 0.1713p274_236\n",
      "169/500 [=========>....................] - ETA: 557s - loss: 0.1711p231_030\n",
      "170/500 [=========>....................] - ETA: 555s - loss: 0.1707p236_269\n",
      "171/500 [=========>....................] - ETA: 554s - loss: 0.1704p287_231\n",
      "172/500 [=========>....................] - ETA: 552s - loss: 0.1703p256_227\n",
      "173/500 [=========>....................] - ETA: 550s - loss: 0.1702p274_065\n",
      "174/500 [=========>....................] - ETA: 549s - loss: 0.1698p243_176\n",
      "175/500 [=========>....................] - ETA: 547s - loss: 0.1693p276_462\n",
      "176/500 [=========>....................] - ETA: 545s - loss: 0.1687p278_314\n",
      "177/500 [=========>....................] - ETA: 544s - loss: 0.1696p227_277\n",
      "178/500 [=========>....................] - ETA: 542s - loss: 0.1694p273_244\n",
      "179/500 [=========>....................] - ETA: 541s - loss: 0.1690p228_095\n",
      "180/500 [=========>....................] - ETA: 539s - loss: 0.1696p243_398\n",
      "181/500 [=========>....................] - ETA: 537s - loss: 0.1696p226_061\n",
      "182/500 [=========>....................] - ETA: 536s - loss: 0.1697p278_190\n",
      "183/500 [=========>....................] - ETA: 534s - loss: 0.1697p279_109\n",
      "184/500 [==========>...................] - ETA: 532s - loss: 0.1696p287_225\n",
      "185/500 [==========>...................] - ETA: 530s - loss: 0.1692p228_242\n",
      "186/500 [==========>...................] - ETA: 529s - loss: 0.1689p239_108\n",
      "187/500 [==========>...................] - ETA: 527s - loss: 0.1689p228_151\n",
      "188/500 [==========>...................] - ETA: 525s - loss: 0.1687p254_049\n",
      "189/500 [==========>...................] - ETA: 524s - loss: 0.1683p278_334\n",
      "190/500 [==========>...................] - ETA: 522s - loss: 0.1680p230_060\n",
      "191/500 [==========>...................] - ETA: 520s - loss: 0.1676p274_075\n",
      "192/500 [==========>...................] - ETA: 519s - loss: 0.1673p259_463\n",
      "193/500 [==========>...................] - ETA: 517s - loss: 0.1671p256_146\n",
      "194/500 [==========>...................] - ETA: 515s - loss: 0.1671p254_396\n",
      "195/500 [==========>...................] - ETA: 514s - loss: 0.1677p231_004\n",
      "196/500 [==========>...................] - ETA: 512s - loss: 0.1675p236_243\n",
      "197/500 [==========>...................] - ETA: 510s - loss: 0.1671p256_014\n",
      "198/500 [==========>...................] - ETA: 509s - loss: 0.1664p244_176\n",
      "199/500 [==========>...................] - ETA: 507s - loss: 0.1661p269_326\n",
      "200/500 [===========>..................] - ETA: 505s - loss: 0.1655p244_189\n",
      "201/500 [===========>..................] - ETA: 504s - loss: 0.1652p233_326\n",
      "202/500 [===========>..................] - ETA: 502s - loss: 0.1648p254_235\n",
      "203/500 [===========>..................] - ETA: 500s - loss: 0.1648p250_316\n",
      "204/500 [===========>..................] - ETA: 498s - loss: 0.1645p282_270\n",
      "205/500 [===========>..................] - ETA: 497s - loss: 0.1654p274_307\n",
      "206/500 [===========>..................] - ETA: 495s - loss: 0.1663p236_263\n",
      "207/500 [===========>..................] - ETA: 494s - loss: 0.1660p244_295\n",
      "208/500 [===========>..................] - ETA: 492s - loss: 0.1656p282_132\n",
      "209/500 [===========>..................] - ETA: 490s - loss: 0.1663p268_299\n",
      "210/500 [===========>..................] - ETA: 489s - loss: 0.1660p276_175\n",
      "211/500 [===========>..................] - ETA: 487s - loss: 0.1664p279_094\n",
      "212/500 [===========>..................] - ETA: 485s - loss: 0.1661p268_252\n",
      "213/500 [===========>..................] - ETA: 484s - loss: 0.1657p250_438\n",
      "214/500 [===========>..................] - ETA: 482s - loss: 0.1654p239_224\n",
      "215/500 [===========>..................] - ETA: 480s - loss: 0.1652p231_123\n",
      "216/500 [===========>..................] - ETA: 479s - loss: 0.1648p287_269\n",
      "217/500 [============>.................] - ETA: 477s - loss: 0.1644p286_171\n",
      "218/500 [============>.................] - ETA: 475s - loss: 0.1658p279_142\n",
      "219/500 [============>.................] - ETA: 474s - loss: 0.1654p250_400\n",
      "220/500 [============>.................] - ETA: 472s - loss: 0.1650p286_231\n",
      "221/500 [============>.................] - ETA: 470s - loss: 0.1655p274_004\n",
      "222/500 [============>.................] - ETA: 469s - loss: 0.1654p278_147\n",
      "223/500 [============>.................] - ETA: 467s - loss: 0.1652p282_248\n",
      "224/500 [============>.................] - ETA: 465s - loss: 0.1647p244_100\n",
      "225/500 [============>.................] - ETA: 464s - loss: 0.1641p287_243\n",
      "226/500 [============>.................] - ETA: 462s - loss: 0.1643p286_186\n",
      "227/500 [============>.................] - ETA: 460s - loss: 0.1641p250_412\n",
      "228/500 [============>.................] - ETA: 459s - loss: 0.1641p228_084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/500 [============>.................] - ETA: 457s - loss: 0.1638p256_311\n",
      "230/500 [============>.................] - ETA: 455s - loss: 0.1633p239_382\n",
      "231/500 [============>.................] - ETA: 453s - loss: 0.1629p258_188\n",
      "232/500 [============>.................] - ETA: 452s - loss: 0.1630p279_223\n",
      "233/500 [============>.................] - ETA: 450s - loss: 0.1628p282_167\n",
      "234/500 [=============>................] - ETA: 448s - loss: 0.1625p274_244\n",
      "235/500 [=============>................] - ETA: 447s - loss: 0.1629p254_282\n",
      "236/500 [=============>................] - ETA: 445s - loss: 0.1627p243_381\n",
      "237/500 [=============>................] - ETA: 443s - loss: 0.1629p244_247\n",
      "238/500 [=============>................] - ETA: 442s - loss: 0.1627p276_067\n",
      "239/500 [=============>................] - ETA: 440s - loss: 0.1624p258_024\n",
      "240/500 [=============>................] - ETA: 438s - loss: 0.1622p236_308\n",
      "241/500 [=============>................] - ETA: 437s - loss: 0.1621p287_044\n",
      "242/500 [=============>................] - ETA: 435s - loss: 0.1618p267_291\n",
      "243/500 [=============>................] - ETA: 433s - loss: 0.1617p231_020\n",
      "244/500 [=============>................] - ETA: 432s - loss: 0.1615p273_376\n",
      "245/500 [=============>................] - ETA: 430s - loss: 0.1613p287_015\n",
      "246/500 [=============>................] - ETA: 428s - loss: 0.1611p236_407\n",
      "247/500 [=============>................] - ETA: 427s - loss: 0.1610p274_363\n",
      "248/500 [=============>................] - ETA: 425s - loss: 0.1611p287_201\n",
      "249/500 [=============>................] - ETA: 423s - loss: 0.1608p286_189\n",
      "250/500 [==============>...............] - ETA: 422s - loss: 0.1606p233_349\n",
      "251/500 [==============>...............] - ETA: 420s - loss: 0.1604p231_062\n",
      "252/500 [==============>...............] - ETA: 418s - loss: 0.1600p233_175\n",
      "253/500 [==============>...............] - ETA: 417s - loss: 0.1599p231_206\n",
      "254/500 [==============>...............] - ETA: 415s - loss: 0.1599p287_052\n",
      "255/500 [==============>...............] - ETA: 413s - loss: 0.1596p259_194\n",
      "256/500 [==============>...............] - ETA: 412s - loss: 0.1591p244_102\n",
      "257/500 [==============>...............] - ETA: 410s - loss: 0.1588p278_104\n",
      "258/500 [==============>...............] - ETA: 408s - loss: 0.1585p273_171\n",
      "259/500 [==============>...............] - ETA: 407s - loss: 0.1582p226_337\n",
      "260/500 [==============>...............] - ETA: 405s - loss: 0.1580p282_205\n",
      "261/500 [==============>...............] - ETA: 403s - loss: 0.1576p270_148\n",
      "262/500 [==============>...............] - ETA: 401s - loss: 0.1575p278_204\n",
      "263/500 [==============>...............] - ETA: 400s - loss: 0.1572p274_092\n",
      "264/500 [==============>...............] - ETA: 398s - loss: 0.1570p258_273\n",
      "265/500 [==============>...............] - ETA: 396s - loss: 0.1566p270_460\n",
      "266/500 [==============>...............] - ETA: 395s - loss: 0.1566p276_282\n",
      "267/500 [===============>..............] - ETA: 393s - loss: 0.1567p226_361\n",
      "268/500 [===============>..............] - ETA: 391s - loss: 0.1566p277_192\n",
      "269/500 [===============>..............] - ETA: 390s - loss: 0.1563p270_377\n",
      "270/500 [===============>..............] - ETA: 388s - loss: 0.1562p244_011\n",
      "271/500 [===============>..............] - ETA: 386s - loss: 0.1558p258_255\n",
      "272/500 [===============>..............] - ETA: 384s - loss: 0.1556p243_253\n",
      "273/500 [===============>..............] - ETA: 383s - loss: 0.1554p256_275\n",
      "274/500 [===============>..............] - ETA: 381s - loss: 0.1553p228_272\n"
     ]
    }
   ],
   "source": [
    "filt_incept_list = [[16, 8, 4, 16, 8]]*14\n",
    "rnn_neu_list = [num_freq,num_freq]\n",
    "v6_1 = build_model(num_freq=129,num_time=128,num_channel=1, filt_incept_list=filt_incept_list, rnn_neu_list=rnn_neu_list, verbose=False)\n",
    "v6_1.summary()\n",
    "######################## Training Parameters ###############################\n",
    "learning_rate = 1e-3;   print('learning_rate',learning_rate)\n",
    "adam_opt = Adam(lr=learning_rate, decay=decay)\n",
    "v6_1.compile(loss='mse' ,optimizer=adam_opt)\n",
    "######################## Checkpoints ###############################\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, min_lr=1e-6, cooldown=5, epsilon=1e-05, verbose=1)\n",
    "CkptFold_det = [  'v6_1',    Ckpt_Mod_Weights_fold, 'v6_1/']\n",
    "ModelCheckpoint_det = ['loss',     1,            True,              True,           1] \n",
    "ckpt = ckpt_saving(CkptFold_det, ModelCheckpoint_det, save_all=True)\n",
    "csv_log = CSVLogger(Weights_path+'v6_1_Trglog.txt', '\\t', append=False)\n",
    "plot_path = plot_path_dir+'v6_1.png'\n",
    "########################### Actual training ##################################\n",
    "try:\n",
    "    history_v6_1 = v6_1.fit_generator( infinite_Gen(batch_size,noise_files_list,Folder_det,num_Det),\n",
    "#                            steps_per_epoch=2, epochs=2, verbose=1, \n",
    "                           steps_per_epoch=steps_per_epoch, epochs=100, verbose=1, \n",
    "                           callbacks=[reduce_lr, csv_log, ckpt], \n",
    "                           validation_data=None, validation_steps=None, shuffle=True, \n",
    "                           initial_epoch=0)\n",
    "    plot_loss(history_v6_1, metric_list=['loss'], title='Loss',  plot_path=plot_path)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nKeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_or_load = 'save'\n",
    "model_path = Weights_path+Archi_dir[:-1]+\"_model_v6_1.json\"\n",
    "weights_path = Weights_path+Archi_dir[:-1]+\"_weights_v6_1.h5\"\n",
    "if save_or_load == 'save':\n",
    "    save_model(v6_1, model_path, weights_path)\n",
    "elif save_or_load == 'load':\n",
    "    v6_1 = load_model(model_path, 'path', weights_path, 'final')\n",
    "    v6_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further training : train_model_v6_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_or_load = 'load'\n",
    "model_path = Weights_path+Archi_dir[:-1]+\"_model_v6_1.json\"\n",
    "weights_path = Weights_path+Archi_dir[:-1]+\"_weights_v6_1.h5\"\n",
    "if save_or_load == 'save':\n",
    "    save_model(v6_1, model_path, weights_path)\n",
    "elif save_or_load == 'load':\n",
    "    v6_2 = load_model(model_path, 'path', weights_path, 'final')\n",
    "    v6_1,history_v6_1 = 0,0\n",
    "######################## Training Parameters ###############################\n",
    "learning_rate = ;   print('learning_rate',learning_rate)\n",
    "adam_opt = Adam(lr=learning_rate, decay=decay)\n",
    "v6_2.compile(loss='mse' ,optimizer=adam_opt)\n",
    "######################## Checkpoints ###############################\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, min_lr=1e-6, cooldown=5, epsilon=1e-05, verbose=1)\n",
    "CkptFold_det = [  'v6_2',    Ckpt_Mod_Weights_fold, 'v6_2/']\n",
    "ModelCheckpoint_det = ['loss',     1,            True,              True,           1] \n",
    "ckpt = ckpt_saving(CkptFold_det, ModelCheckpoint_det, save_all=True)\n",
    "csv_log = CSVLogger(Weights_path+'v6_2_Trglog.txt', '\\t', append=False)\n",
    "plot_path = plot_path_dir+'v6_2.png'\n",
    "########################### Actual training ##################################\n",
    "try:\n",
    "    history_v6_2 = v6_2.fit_generator( infinite_Gen(batch_size,noise_files_list,Folder_det,num_Det),\n",
    "                           steps_per_epoch=steps_per_epoch, epochs=100, verbose=1, \n",
    "                           callbacks=[reduce_lr, csv_log, ckpt], \n",
    "                           validation_data=None, validation_steps=None, shuffle=True, \n",
    "                           initial_epoch=100)\n",
    "    plot_loss(history_v6_2, metric_list=['loss'], title='Loss',  plot_path=plot_path)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nKeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model : v1/Logs/v1_model_v1_2.json\n",
      "Saved weights : v1/Logs/v1_weights_v1_2.h5\n"
     ]
    }
   ],
   "source": [
    "save_or_load = 'save'\n",
    "model_path = Weights_path+Archi_dir[:-1]+\"_model_v1_2.json\"\n",
    "weights_path = Weights_path+Archi_dir[:-1]+\"_weights_v1_2.h5\"\n",
    "if save_or_load == 'save':\n",
    "    save_model(train_model_v1_2, model_path, weights_path)\n",
    "elif save_or_load == 'load':\n",
    "    train_model_v1_2 = load_model(model_path, 'path', weights_path, 'final')\n",
    "    train_model_v1_2.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
