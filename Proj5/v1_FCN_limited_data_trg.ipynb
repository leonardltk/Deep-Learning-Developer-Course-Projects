{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from _helper_basics_ import *\n",
    "from _helper_gender_ import *\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.0.8\n",
      "tensorflow 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "## To get helper functions from another folder\n",
    "# sys.path.insert(0, '../') # if _helper_basics_ is in previous folder\n",
    "now_i_am_at = 'home' # home dso test\n",
    "if now_i_am_at=='home': sys.path.insert(0, 'E:/Leonard HDD/Dropbox/DSO/Tasks/')\n",
    "elif now_i_am_at=='dso': sys.path.insert(0, 'D:/Dropbox/DSO/Tasks')\n",
    "\n",
    "from _helper_basics_ import *\n",
    "from _helper_gender_ import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print('keras',      keras.__version__)\n",
    "print('tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfft:256 hop_length:85 \n",
      "num_freq:129 num_time:48 num_channel:1\n"
     ]
    }
   ],
   "source": [
    "sr = 8000\n",
    "\n",
    "nfft = 256\n",
    "hop_length = nfft//3 # 256 = 30ms\n",
    "\n",
    "num_freq,num_time,num_channel    = nfft//2+1,48,1 # 0.5 seconds speech is about 48 time_samples\n",
    "\n",
    "print('nfft:{}'.format(nfft),'hop_length:{}'.format(hop_length),\n",
    "      '\\nnum_freq:{}'.format(num_freq),'num_time:{}'.format(num_time),'num_channel:{}'.format(num_channel))\n",
    "\n",
    "Spect_Det = [nfft, hop_length, num_freq,num_time,num_channel]\n",
    "\n",
    "pwd = os.getcwd()\n",
    "Dataset_dir = os.path.join(pwd,'..','..','..','Speech Audio Text','3) Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Leonard HDD\\\\Dropbox\\\\Meetup\\\\Deep Learning Developer Course\\\\Personal2_Gender_Audio_Classification\\\\Data_tdt\\\\train\\\\X_train',\n",
       " 'E:\\\\Leonard HDD\\\\Dropbox\\\\Meetup\\\\Deep Learning Developer Course\\\\Personal2_Gender_Audio_Classification\\\\Data_tdt\\\\train\\\\X_train_lps',\n",
       " 'E:\\\\Leonard HDD\\\\Dropbox\\\\Meetup\\\\Deep Learning Developer Course\\\\Personal2_Gender_Audio_Classification\\\\Data_tdt\\\\train\\\\X_train_wav',\n",
       " 'E:\\\\Leonard HDD\\\\Dropbox\\\\Meetup\\\\Deep Learning Developer Course\\\\Personal2_Gender_Audio_Classification\\\\Data_tdt\\\\train\\\\Y_train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = os.getcwd() # 'D:\\\\Dropbox\\\\Meetup\\\\Deep Learning Developer Course\\\\Personal2_Gender_Audio_Classification'\n",
    "Data_tdt = os.path.join(pwd,'Data_tdt')\n",
    "trg_dir = os.path.join(Data_tdt,'train')\n",
    "glob.glob(os.path.join(trg_dir,'*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train (9947, 2)\n",
      "X_train (9947, 129, 48, 1)\n",
      "Y_val (3266, 2)\n",
      "X_val (3266, 129, 48, 1)\n",
      "Y_test (3692, 2)\n",
      "X_test (3692, 129, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "yf = np.asarray([0,1])\n",
    "ym = np.asarray([1,0])\n",
    "\n",
    "# X_train_wav = dump_load_pickle(os.path.join(pwd,'Data_tdt','train','X_train_wav'), 'load')\n",
    "# X_train_lps = dump_load_pickle(os.path.join(pwd,'Data_tdt','train','X_train_lps'), 'load')\n",
    "Y_train = dump_load_pickle(os.path.join(pwd,'Data_tdt','train','Y_train'), 'load')\n",
    "X_train = dump_load_pickle(os.path.join(pwd,'Data_tdt','train','X_train'), 'load')\n",
    "\n",
    "# X_val_wav = dump_load_pickle(os.path.join(pwd,'Data_tdt','val','X_val_wav'), 'load')\n",
    "# X_val_lps = dump_load_pickle(os.path.join(pwd,'Data_tdt','val','X_val_lps'), 'load')\n",
    "Y_val = dump_load_pickle(os.path.join(pwd,'Data_tdt','val','Y_val'), 'load')\n",
    "X_val = dump_load_pickle(os.path.join(pwd,'Data_tdt','val','X_val'), 'load')\n",
    "\n",
    "# X_test_wav = dump_load_pickle(os.path.join(pwd,'Data_tdt','test','X_test_wav'), 'load')\n",
    "# X_test_lps = dump_load_pickle(os.path.join(pwd,'Data_tdt','test','X_test_lps'), 'load')\n",
    "Y_test = dump_load_pickle(os.path.join(pwd,'Data_tdt','test','Y_test'), 'load')\n",
    "X_test = dump_load_pickle(os.path.join(pwd,'Data_tdt','test','X_test'), 'load')\n",
    "\n",
    "print('Y_train', Y_train.shape)\n",
    "print('X_train', X_train.shape)\n",
    "print('Y_val', Y_val.shape)\n",
    "print('X_val', X_val.shape)\n",
    "print('Y_test', Y_test.shape)\n",
    "print('X_test', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indicies = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indicies)\n",
    "X_train,Y_train = X_train[indicies],Y_train[indicies]\n",
    "\n",
    "indicies = np.arange(X_val.shape[0])\n",
    "np.random.shuffle(indicies)\n",
    "X_val,Y_val = X_val[indicies],Y_val[indicies]\n",
    "\n",
    "indicies = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(indicies)\n",
    "X_test,Y_test = X_test[indicies],Y_test[indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/8AAAEvCAYAAAATo3FQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14587ee1470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Random batch observation\n",
    "\n",
    "idx = np.random.randint(0,X_train.shape[0])\n",
    "\n",
    "k=2;col=1;l=1; plt.figure(figsize=(16,4*k)); \n",
    "plt.subplot(k,col,l); display_audio(X_train[idx,:,:,0], None, sr, 'spec', hop_length=hop_length,colorbar=1); l+=1\n",
    "plt.tight_layout()\n",
    "if np.argmax(Y_train[idx])   == np.argmax(ym) : print('male')\n",
    "elif np.argmax(Y_train[idx]) == np.argmax(yf) : print('female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIMIT_Gender_Folder = os.path.join(pwd, 'TIMIT_Gender')\n",
    "\n",
    "# print( get_immediate_subdirectories(Data_3_dir) )\n",
    "# trg_dir  = os.path.join(Data_3_dir, 'timit_train')\n",
    "# print('len(trg_dir)',len(trg_dir))\n",
    "# trg_path_list = glob.glob( os.path.join(trg_dir, '*.wav') )\n",
    "# print('len(trg_path_list)',len(trg_path_list))\n",
    "# trg_list = []\n",
    "# for i in trg_path_list: trg_list.append( i[len(trg_dir)+1:] )\n",
    "    \n",
    "X_train_wav = dump_load_pickle(os.path.join(TIMIT_Gender_Folder,'train','X_train_wav'), 'load')\n",
    "X_train_lps = dump_load_pickle(os.path.join(TIMIT_Gender_Folder,'train','X_train_lps'), 'load')\n",
    "Y_train     = dump_load_pickle(os.path.join(TIMIT_Gender_Folder,'train','Y_train'), 'load')\n",
    "X_train     = dump_load_pickle(os.path.join(TIMIT_Gender_Folder,'train','X_train'), 'load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_wav 4619\n",
      "X_train_lps 4619\n",
      "Y_train (40739, 2)\n",
      "X_train (40739, 129, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(Y_train))\n",
    "Y_train = Y_train[indices]\n",
    "X_train = X_train[indices]\n",
    "print('X_train_wav',len(X_train_wav))\n",
    "print('X_train_lps',len(X_train_lps))\n",
    "print('Y_train',Y_train.shape)\n",
    "print('X_train',X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archi_dir v1_2_FCN_limited/\n",
      "Weights_path v1_2_FCN_limited/Logs/\n",
      "Ckpt_Mod_Weights_fold v1_2_FCN_limited/Checkpoint_Model_Weights/\n",
      "plot_path_dir v1_2_FCN_limited/Plots/\n"
     ]
    }
   ],
   "source": [
    "Archi_dir = \"v1_2_FCN_limited/\"\n",
    "Weights_path = Archi_dir+\"Logs/\"\n",
    "Ckpt_Mod_Weights_fold = Archi_dir+\"Checkpoint_Model_Weights/\"\n",
    "plot_path_dir = Archi_dir+'Plots/'\n",
    "if not os.path.exists(Archi_dir): os.mkdir(Archi_dir)\n",
    "if not os.path.exists(Weights_path): os.mkdir(Weights_path)\n",
    "if not os.path.exists(Ckpt_Mod_Weights_fold): os.mkdir(Ckpt_Mod_Weights_fold)\n",
    "if not os.path.exists(plot_path_dir): os.mkdir(plot_path_dir)\n",
    "print('Archi_dir',Archi_dir)\n",
    "print('Weights_path',Weights_path)\n",
    "print('Ckpt_Mod_Weights_fold',Ckpt_Mod_Weights_fold)\n",
    "print('plot_path_dir',plot_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 85, 129, 48, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spect_Det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay 0\n",
      "steps_per_epoch 500\n",
      "epochs 150\n",
      "batch_size 32\n"
     ]
    }
   ],
   "source": [
    "######################## Training Parameters ###############################\n",
    "decay = 0;          \tprint('decay',decay)\n",
    "steps_per_epoch = 500;\tprint('steps_per_epoch',steps_per_epoch)\n",
    "epochs = 150;\t\t\tprint('epochs',epochs)\n",
    "batch_size = 32;   \t\tprint('batch_size',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1_1\n",
    "    conv_list = [64]*4\n",
    "    dense_list = [200, 200, 2]\n",
    "    no max pooling\n",
    "    only global pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 129, 48, 1)        0         \n",
      "_________________________________________________________________\n",
      "0_Conv2D (Conv2D)            (None, 129, 48, 64)       640       \n",
      "_________________________________________________________________\n",
      "1_Conv2D (Conv2D)            (None, 129, 48, 64)       36928     \n",
      "_________________________________________________________________\n",
      "1_Pool (MaxPooling2D)        (None, 64, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "2_Conv2D (Conv2D)            (None, 64, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "GlobalPool (GlobalAveragePoo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "3_Dense (Dense)              (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "4_Dense (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "5_Output (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 107,798\n",
      "Trainable params: 107,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "learning_rate 0.001\n",
      "ckpt_path :  v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-{epoch:04d}_L-{loss:.2f}.hdf5 \n",
      "\n",
      "Train on 777 samples, validate on 195 samples\n",
      "Epoch 1/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 1.3392 - categorical_accuracy: 0.5299Epoch 00000: loss improved from inf to 1.33076, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0000_L-1.33.hdf5\n",
      "777/777 [==============================] - 8s - loss: 1.3308 - categorical_accuracy: 0.5315 - val_loss: 1.0926 - val_categorical_accuracy: 0.5077\n",
      "Epoch 2/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.8286 - categorical_accuracy: 0.5482Epoch 00001: loss improved from 1.33076 to 0.82842, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0001_L-0.83.hdf5\n",
      "777/777 [==============================] - 7s - loss: 0.8284 - categorical_accuracy: 0.5470 - val_loss: 0.7863 - val_categorical_accuracy: 0.5077\n",
      "Epoch 3/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.7240 - categorical_accuracy: 0.5638Epoch 00002: loss improved from 0.82842 to 0.72401, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0002_L-0.72.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.7240 - categorical_accuracy: 0.5624 - val_loss: 0.5878 - val_categorical_accuracy: 0.8462\n",
      "Epoch 4/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.5694 - categorical_accuracy: 0.7018Epoch 00003: loss improved from 0.72401 to 0.56849, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0003_L-0.57.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.5685 - categorical_accuracy: 0.7040 - val_loss: 0.4793 - val_categorical_accuracy: 0.8256\n",
      "Epoch 5/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.4240 - categorical_accuracy: 0.8424Epoch 00004: loss improved from 0.56849 to 0.42129, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0004_L-0.42.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.4213 - categorical_accuracy: 0.8443 - val_loss: 0.4970 - val_categorical_accuracy: 0.7385\n",
      "Epoch 6/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.3362 - categorical_accuracy: 0.8685Epoch 00005: loss improved from 0.42129 to 0.33485, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0005_L-0.33.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.3349 - categorical_accuracy: 0.8687 - val_loss: 0.4033 - val_categorical_accuracy: 0.7795\n",
      "Epoch 7/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.2292 - categorical_accuracy: 0.9336Epoch 00006: loss improved from 0.33485 to 0.22937, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0006_L-0.23.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.2294 - categorical_accuracy: 0.9331 - val_loss: 0.2390 - val_categorical_accuracy: 0.9333\n",
      "Epoch 8/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1656 - categorical_accuracy: 0.9440Epoch 00007: loss improved from 0.22937 to 0.16551, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0007_L-0.17.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.1655 - categorical_accuracy: 0.9434 - val_loss: 0.1742 - val_categorical_accuracy: 0.9282\n",
      "Epoch 9/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1465 - categorical_accuracy: 0.9544Epoch 00008: loss improved from 0.16551 to 0.14592, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0008_L-0.15.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.1459 - categorical_accuracy: 0.9550 - val_loss: 0.2167 - val_categorical_accuracy: 0.8923\n",
      "Epoch 10/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1436 - categorical_accuracy: 0.9479Epoch 00009: loss improved from 0.14592 to 0.14303, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0009_L-0.14.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.1430 - categorical_accuracy: 0.9485 - val_loss: 0.1366 - val_categorical_accuracy: 0.9538\n",
      "Epoch 11/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.9479Epoch 00010: loss improved from 0.14303 to 0.12056, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0010_L-0.12.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.1206 - categorical_accuracy: 0.9485 - val_loss: 0.1714 - val_categorical_accuracy: 0.9077\n",
      "Epoch 12/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1125 - categorical_accuracy: 0.9609Epoch 00011: loss improved from 0.12056 to 0.11356, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0011_L-0.11.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.1136 - categorical_accuracy: 0.9601 - val_loss: 0.1634 - val_categorical_accuracy: 0.9487\n",
      "Epoch 13/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.9596Epoch 00012: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.1237 - categorical_accuracy: 0.9601 - val_loss: 0.1525 - val_categorical_accuracy: 0.9590\n",
      "Epoch 14/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1113 - categorical_accuracy: 0.9635Epoch 00013: loss improved from 0.11356 to 0.11037, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0013_L-0.11.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.1104 - categorical_accuracy: 0.9640 - val_loss: 0.1100 - val_categorical_accuracy: 0.9641\n",
      "Epoch 15/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0943 - categorical_accuracy: 0.9661Epoch 00014: loss improved from 0.11037 to 0.09417, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0014_L-0.09.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0942 - categorical_accuracy: 0.9665 - val_loss: 0.1029 - val_categorical_accuracy: 0.9692\n",
      "Epoch 16/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.1102 - categorical_accuracy: 0.9557Epoch 00015: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.1098 - categorical_accuracy: 0.9562 - val_loss: 0.1179 - val_categorical_accuracy: 0.9590\n",
      "Epoch 17/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0838 - categorical_accuracy: 0.9674Epoch 00016: loss improved from 0.09417 to 0.08368, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0016_L-0.08.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0837 - categorical_accuracy: 0.9678 - val_loss: 0.0991 - val_categorical_accuracy: 0.9692\n",
      "Epoch 18/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9714Epoch 00017: loss improved from 0.08368 to 0.08212, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0017_L-0.08.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0821 - categorical_accuracy: 0.9717 - val_loss: 0.0943 - val_categorical_accuracy: 0.9590\n",
      "Epoch 19/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0811 - categorical_accuracy: 0.9674Epoch 00018: loss improved from 0.08212 to 0.08079, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0018_L-0.08.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0808 - categorical_accuracy: 0.9678 - val_loss: 0.0969 - val_categorical_accuracy: 0.9641\n",
      "Epoch 20/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0738 - categorical_accuracy: 0.9727Epoch 00019: loss improved from 0.08079 to 0.07298, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0019_L-0.07.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0730 - categorical_accuracy: 0.9730 - val_loss: 0.0914 - val_categorical_accuracy: 0.9538\n",
      "Epoch 21/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0733 - categorical_accuracy: 0.9727Epoch 00020: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0733 - categorical_accuracy: 0.9730 - val_loss: 0.0962 - val_categorical_accuracy: 0.9590\n",
      "Epoch 22/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0738 - categorical_accuracy: 0.9727Epoch 00021: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0745 - categorical_accuracy: 0.9717 - val_loss: 0.0877 - val_categorical_accuracy: 0.9692\n",
      "Epoch 23/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0761 - categorical_accuracy: 0.9740Epoch 00022: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0755 - categorical_accuracy: 0.9743 - val_loss: 0.0902 - val_categorical_accuracy: 0.9641\n",
      "Epoch 24/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0770 - categorical_accuracy: 0.9674Epoch 00023: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0764 - categorical_accuracy: 0.9678 - val_loss: 0.0897 - val_categorical_accuracy: 0.9538\n",
      "Epoch 25/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0715 - categorical_accuracy: 0.9753Epoch 00024: loss improved from 0.07298 to 0.07201, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0024_L-0.07.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0720 - categorical_accuracy: 0.9743 - val_loss: 0.0904 - val_categorical_accuracy: 0.9692\n",
      "Epoch 26/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0722 - categorical_accuracy: 0.9779Epoch 00025: loss improved from 0.07201 to 0.07141, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0025_L-0.07.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0714 - categorical_accuracy: 0.9781 - val_loss: 0.0899 - val_categorical_accuracy: 0.9590\n",
      "Epoch 27/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0651 - categorical_accuracy: 0.9766Epoch 00026: loss improved from 0.07141 to 0.06475, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0026_L-0.06.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0648 - categorical_accuracy: 0.9768 - val_loss: 0.0811 - val_categorical_accuracy: 0.9744\n",
      "Epoch 28/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0630 - categorical_accuracy: 0.9766Epoch 00027: loss improved from 0.06475 to 0.06231, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0027_L-0.06.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0623 - categorical_accuracy: 0.9768 - val_loss: 0.0894 - val_categorical_accuracy: 0.9590\n",
      "Epoch 29/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0677 - categorical_accuracy: 0.9766Epoch 00028: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0670 - categorical_accuracy: 0.9768 - val_loss: 0.1081 - val_categorical_accuracy: 0.9385\n",
      "Epoch 30/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0771 - categorical_accuracy: 0.9714Epoch 00029: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0762 - categorical_accuracy: 0.9717 - val_loss: 0.0807 - val_categorical_accuracy: 0.9744\n",
      "Epoch 31/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0672 - categorical_accuracy: 0.9753Epoch 00030: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0679 - categorical_accuracy: 0.9743 - val_loss: 0.0872 - val_categorical_accuracy: 0.9744\n",
      "Epoch 32/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0751 - categorical_accuracy: 0.9740Epoch 00031: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0754 - categorical_accuracy: 0.9743 - val_loss: 0.0808 - val_categorical_accuracy: 0.9641\n",
      "Epoch 33/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0718 - categorical_accuracy: 0.9714Epoch 00032: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0710 - categorical_accuracy: 0.9717 - val_loss: 0.0834 - val_categorical_accuracy: 0.9641\n",
      "Epoch 34/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0646 - categorical_accuracy: 0.9792Epoch 00033: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0643 - categorical_accuracy: 0.9794 - val_loss: 0.0790 - val_categorical_accuracy: 0.9744\n",
      "Epoch 35/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0605 - categorical_accuracy: 0.9792Epoch 00034: loss improved from 0.06231 to 0.06040, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0034_L-0.06.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0604 - categorical_accuracy: 0.9794 - val_loss: 0.0779 - val_categorical_accuracy: 0.9744\n",
      "Epoch 36/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0653 - categorical_accuracy: 0.9753Epoch 00035: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0647 - categorical_accuracy: 0.9755 - val_loss: 0.0770 - val_categorical_accuracy: 0.9692\n",
      "Epoch 37/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0609 - categorical_accuracy: 0.9792Epoch 00036: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0609 - categorical_accuracy: 0.9794 - val_loss: 0.0794 - val_categorical_accuracy: 0.9641\n",
      "Epoch 38/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0583 - categorical_accuracy: 0.9792Epoch 00037: loss improved from 0.06040 to 0.05774, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0037_L-0.06.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0577 - categorical_accuracy: 0.9794 - val_loss: 0.0903 - val_categorical_accuracy: 0.9641\n",
      "Epoch 39/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0564 - categorical_accuracy: 0.9857Epoch 00038: loss improved from 0.05774 to 0.05576, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0038_L-0.06.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0558 - categorical_accuracy: 0.9858 - val_loss: 0.0874 - val_categorical_accuracy: 0.9590\n",
      "Epoch 40/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0580 - categorical_accuracy: 0.9792Epoch 00039: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0573 - categorical_accuracy: 0.9794 - val_loss: 0.0904 - val_categorical_accuracy: 0.9692\n",
      "Epoch 41/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0619 - categorical_accuracy: 0.9818Epoch 00040: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0630 - categorical_accuracy: 0.9807 - val_loss: 0.0809 - val_categorical_accuracy: 0.9641\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/777 [============================>.] - ETA: 0s - loss: 0.0605 - categorical_accuracy: 0.9779Epoch 00041: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0644 - categorical_accuracy: 0.9755 - val_loss: 0.0854 - val_categorical_accuracy: 0.9590\n",
      "Epoch 43/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9648Epoch 00042: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0802 - categorical_accuracy: 0.9653 - val_loss: 0.0893 - val_categorical_accuracy: 0.9744\n",
      "Epoch 44/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0701 - categorical_accuracy: 0.9740Epoch 00043: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0695 - categorical_accuracy: 0.9743 - val_loss: 0.1002 - val_categorical_accuracy: 0.9692\n",
      "Epoch 45/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0581 - categorical_accuracy: 0.9818Epoch 00044: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0575 - categorical_accuracy: 0.9820 - val_loss: 0.0876 - val_categorical_accuracy: 0.9744\n",
      "Epoch 46/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0572 - categorical_accuracy: 0.9818Epoch 00045: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0571 - categorical_accuracy: 0.9820 - val_loss: 0.0761 - val_categorical_accuracy: 0.9641\n",
      "Epoch 47/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0557 - categorical_accuracy: 0.9805Epoch 00046: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0620 - categorical_accuracy: 0.9794 - val_loss: 0.0785 - val_categorical_accuracy: 0.9744\n",
      "Epoch 48/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0624 - categorical_accuracy: 0.9766Epoch 00047: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0625 - categorical_accuracy: 0.9768 - val_loss: 0.0772 - val_categorical_accuracy: 0.9744\n",
      "Epoch 49/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0612 - categorical_accuracy: 0.9766Epoch 00048: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0607 - categorical_accuracy: 0.9768 - val_loss: 0.0996 - val_categorical_accuracy: 0.9487\n",
      "Epoch 50/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0692 - categorical_accuracy: 0.9740Epoch 00049: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0686 - categorical_accuracy: 0.9743 - val_loss: 0.1130 - val_categorical_accuracy: 0.9436\n",
      "Epoch 51/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0680 - categorical_accuracy: 0.9779Epoch 00050: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0672 - categorical_accuracy: 0.9781 - val_loss: 0.0950 - val_categorical_accuracy: 0.9590\n",
      "Epoch 52/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0560 - categorical_accuracy: 0.9792Epoch 00051: loss improved from 0.05576 to 0.05550, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0051_L-0.06.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0555 - categorical_accuracy: 0.9794 - val_loss: 0.0729 - val_categorical_accuracy: 0.9692\n",
      "Epoch 53/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0513 - categorical_accuracy: 0.9805Epoch 00052: loss improved from 0.05550 to 0.05073, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0052_L-0.05.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0507 - categorical_accuracy: 0.9807 - val_loss: 0.0838 - val_categorical_accuracy: 0.9744\n",
      "Epoch 54/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0606 - categorical_accuracy: 0.9805Epoch 00053: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0599 - categorical_accuracy: 0.9807 - val_loss: 0.0835 - val_categorical_accuracy: 0.9692\n",
      "Epoch 55/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0562 - categorical_accuracy: 0.9779Epoch 00054: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0564 - categorical_accuracy: 0.9781 - val_loss: 0.0736 - val_categorical_accuracy: 0.9744\n",
      "Epoch 56/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0504 - categorical_accuracy: 0.9818Epoch 00055: loss improved from 0.05073 to 0.04988, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0055_L-0.05.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0499 - categorical_accuracy: 0.9820 - val_loss: 0.0846 - val_categorical_accuracy: 0.9744\n",
      "Epoch 57/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0534 - categorical_accuracy: 0.9844Epoch 00056: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0530 - categorical_accuracy: 0.9846 - val_loss: 0.0781 - val_categorical_accuracy: 0.9692\n",
      "Epoch 58/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0531 - categorical_accuracy: 0.9844Epoch 00057: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0525 - categorical_accuracy: 0.9846 - val_loss: 0.0757 - val_categorical_accuracy: 0.9692\n",
      "Epoch 59/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0541 - categorical_accuracy: 0.9831Epoch 00058: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0535 - categorical_accuracy: 0.9833 - val_loss: 0.0735 - val_categorical_accuracy: 0.9692\n",
      "Epoch 60/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0540 - categorical_accuracy: 0.9818Epoch 00059: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0533 - categorical_accuracy: 0.9820 - val_loss: 0.0814 - val_categorical_accuracy: 0.9744\n",
      "Epoch 61/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0542 - categorical_accuracy: 0.9805Epoch 00060: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0535 - categorical_accuracy: 0.9807 - val_loss: 0.0715 - val_categorical_accuracy: 0.9744\n",
      "Epoch 62/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0493 - categorical_accuracy: 0.9805Epoch 00061: loss improved from 0.04988 to 0.04883, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0061_L-0.05.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0488 - categorical_accuracy: 0.9807 - val_loss: 0.0733 - val_categorical_accuracy: 0.9641\n",
      "Epoch 63/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0490 - categorical_accuracy: 0.9844Epoch 00062: loss improved from 0.04883 to 0.04851, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0062_L-0.05.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0485 - categorical_accuracy: 0.9846 - val_loss: 0.0719 - val_categorical_accuracy: 0.9744\n",
      "Epoch 64/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0465 - categorical_accuracy: 0.9857Epoch 00063: loss improved from 0.04851 to 0.04600, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0063_L-0.05.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0460 - categorical_accuracy: 0.9858 - val_loss: 0.0715 - val_categorical_accuracy: 0.9641\n",
      "Epoch 65/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0470 - categorical_accuracy: 0.9844Epoch 00064: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0470 - categorical_accuracy: 0.9846 - val_loss: 0.0718 - val_categorical_accuracy: 0.9692\n",
      "Epoch 66/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0432 - categorical_accuracy: 0.9870Epoch 00065: loss improved from 0.04600 to 0.04580, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0065_L-0.05.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0458 - categorical_accuracy: 0.9846 - val_loss: 0.0725 - val_categorical_accuracy: 0.9744\n",
      "Epoch 67/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0548 - categorical_accuracy: 0.9727Epoch 00066: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0594 - categorical_accuracy: 0.9717 - val_loss: 0.1091 - val_categorical_accuracy: 0.9538\n",
      "Epoch 68/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0583 - categorical_accuracy: 0.9766Epoch 00067: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0588 - categorical_accuracy: 0.9755 - val_loss: 0.0776 - val_categorical_accuracy: 0.9795\n",
      "Epoch 69/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0450 - categorical_accuracy: 0.9857Epoch 00068: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0470 - categorical_accuracy: 0.9846 - val_loss: 0.0845 - val_categorical_accuracy: 0.9692\n",
      "Epoch 70/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0537 - categorical_accuracy: 0.9805Epoch 00069: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0532 - categorical_accuracy: 0.9807 - val_loss: 0.1048 - val_categorical_accuracy: 0.9538\n",
      "Epoch 71/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0439 - categorical_accuracy: 0.9857Epoch 00070: loss improved from 0.04580 to 0.04340, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0070_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0434 - categorical_accuracy: 0.9858 - val_loss: 0.0730 - val_categorical_accuracy: 0.9692\n",
      "Epoch 72/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0437 - categorical_accuracy: 0.9870Epoch 00071: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0442 - categorical_accuracy: 0.9871 - val_loss: 0.0697 - val_categorical_accuracy: 0.9692\n",
      "Epoch 73/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0496 - categorical_accuracy: 0.9844Epoch 00072: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0493 - categorical_accuracy: 0.9846 - val_loss: 0.0850 - val_categorical_accuracy: 0.9590\n",
      "Epoch 74/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0511 - categorical_accuracy: 0.9831Epoch 00073: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0506 - categorical_accuracy: 0.9833 - val_loss: 0.0843 - val_categorical_accuracy: 0.9590\n",
      "Epoch 75/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0457 - categorical_accuracy: 0.9883Epoch 00074: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0465 - categorical_accuracy: 0.9871 - val_loss: 0.0693 - val_categorical_accuracy: 0.9744\n",
      "Epoch 76/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0426 - categorical_accuracy: 0.9922Epoch 00075: loss improved from 0.04340 to 0.04214, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0075_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0421 - categorical_accuracy: 0.9923 - val_loss: 0.0706 - val_categorical_accuracy: 0.9692\n",
      "Epoch 77/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0507 - categorical_accuracy: 0.9844Epoch 00076: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0501 - categorical_accuracy: 0.9846 - val_loss: 0.0737 - val_categorical_accuracy: 0.9641\n",
      "Epoch 78/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0443 - categorical_accuracy: 0.9818Epoch 00077: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0456 - categorical_accuracy: 0.9807 - val_loss: 0.0736 - val_categorical_accuracy: 0.9692\n",
      "Epoch 79/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0438 - categorical_accuracy: 0.9844Epoch 00078: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0435 - categorical_accuracy: 0.9846 - val_loss: 0.0705 - val_categorical_accuracy: 0.9590\n",
      "Epoch 80/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0424 - categorical_accuracy: 0.9857Epoch 00079: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0435 - categorical_accuracy: 0.9846 - val_loss: 0.0733 - val_categorical_accuracy: 0.9641\n",
      "Epoch 81/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0431 - categorical_accuracy: 0.9883Epoch 00080: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0439 - categorical_accuracy: 0.9871 - val_loss: 0.0889 - val_categorical_accuracy: 0.9744\n",
      "Epoch 82/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0498 - categorical_accuracy: 0.9805Epoch 00081: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0498 - categorical_accuracy: 0.9807 - val_loss: 0.0795 - val_categorical_accuracy: 0.9692\n",
      "Epoch 83/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0432 - categorical_accuracy: 0.9857Epoch 00082: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0427 - categorical_accuracy: 0.9858 - val_loss: 0.0766 - val_categorical_accuracy: 0.9692\n",
      "Epoch 84/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0435 - categorical_accuracy: 0.9857Epoch 00083: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0430 - categorical_accuracy: 0.9858 - val_loss: 0.0709 - val_categorical_accuracy: 0.9692\n",
      "Epoch 85/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0429 - categorical_accuracy: 0.9818Epoch 00084: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0425 - categorical_accuracy: 0.9820 - val_loss: 0.0701 - val_categorical_accuracy: 0.9692\n",
      "Epoch 86/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0409 - categorical_accuracy: 0.9870Epoch 00085: loss improved from 0.04214 to 0.04055, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0085_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0405 - categorical_accuracy: 0.9871 - val_loss: 0.0685 - val_categorical_accuracy: 0.9641\n",
      "Epoch 87/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0399 - categorical_accuracy: 0.9883Epoch 00086: loss improved from 0.04055 to 0.03946, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0086_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0395 - categorical_accuracy: 0.9884 - val_loss: 0.0695 - val_categorical_accuracy: 0.9692\n",
      "Epoch 88/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0423 - categorical_accuracy: 0.9857Epoch 00087: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0419 - categorical_accuracy: 0.9858 - val_loss: 0.0688 - val_categorical_accuracy: 0.9744\n",
      "Epoch 89/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0351 - categorical_accuracy: 0.9922Epoch 00088: loss improved from 0.03946 to 0.03921, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0088_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0392 - categorical_accuracy: 0.9897 - val_loss: 0.0695 - val_categorical_accuracy: 0.9692\n",
      "Epoch 90/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0532 - categorical_accuracy: 0.9792Epoch 00089: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0532 - categorical_accuracy: 0.9794 - val_loss: 0.0763 - val_categorical_accuracy: 0.9795\n",
      "Epoch 91/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0396 - categorical_accuracy: 0.9857Epoch 00090: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0398 - categorical_accuracy: 0.9858 - val_loss: 0.0727 - val_categorical_accuracy: 0.9641\n",
      "Epoch 92/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0414 - categorical_accuracy: 0.9857Epoch 00091: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0415 - categorical_accuracy: 0.9858 - val_loss: 0.0672 - val_categorical_accuracy: 0.9692\n",
      "Epoch 93/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0428 - categorical_accuracy: 0.9831Epoch 00092: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777/777 [==============================] - 6s - loss: 0.0423 - categorical_accuracy: 0.9833 - val_loss: 0.0679 - val_categorical_accuracy: 0.9744\n",
      "Epoch 94/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0333 - categorical_accuracy: 0.9896Epoch 00093: loss improved from 0.03921 to 0.03741, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0093_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0374 - categorical_accuracy: 0.9884 - val_loss: 0.0714 - val_categorical_accuracy: 0.9744\n",
      "Epoch 95/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0488 - categorical_accuracy: 0.9831Epoch 00094: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0482 - categorical_accuracy: 0.9833 - val_loss: 0.0689 - val_categorical_accuracy: 0.9795\n",
      "Epoch 96/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0396 - categorical_accuracy: 0.9857Epoch 00095: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0401 - categorical_accuracy: 0.9858 - val_loss: 0.0758 - val_categorical_accuracy: 0.9641\n",
      "Epoch 97/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0407 - categorical_accuracy: 0.9831Epoch 00096: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0405 - categorical_accuracy: 0.9833 - val_loss: 0.0678 - val_categorical_accuracy: 0.9692\n",
      "Epoch 98/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0393 - categorical_accuracy: 0.9870Epoch 00097: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0388 - categorical_accuracy: 0.9871 - val_loss: 0.0680 - val_categorical_accuracy: 0.9744\n",
      "Epoch 99/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0351 - categorical_accuracy: 0.9922Epoch 00098: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0378 - categorical_accuracy: 0.9910 - val_loss: 0.0681 - val_categorical_accuracy: 0.9641\n",
      "Epoch 100/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0374 - categorical_accuracy: 0.9909Epoch 00099: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0391 - categorical_accuracy: 0.9897 - val_loss: 0.0674 - val_categorical_accuracy: 0.9641\n",
      "Epoch 101/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0381 - categorical_accuracy: 0.9857Epoch 00100: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0377 - categorical_accuracy: 0.9858 - val_loss: 0.0680 - val_categorical_accuracy: 0.9744\n",
      "Epoch 102/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0407 - categorical_accuracy: 0.9857Epoch 00101: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0403 - categorical_accuracy: 0.9858 - val_loss: 0.0747 - val_categorical_accuracy: 0.9641\n",
      "Epoch 103/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0387 - categorical_accuracy: 0.9870Epoch 00102: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0407 - categorical_accuracy: 0.9858 - val_loss: 0.0692 - val_categorical_accuracy: 0.9744\n",
      "Epoch 104/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0384 - categorical_accuracy: 0.9870Epoch 00103: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0382 - categorical_accuracy: 0.9871 - val_loss: 0.0707 - val_categorical_accuracy: 0.9692\n",
      "Epoch 105/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0383 - categorical_accuracy: 0.9896Epoch 00104: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0379 - categorical_accuracy: 0.9897 - val_loss: 0.0715 - val_categorical_accuracy: 0.9590\n",
      "Epoch 106/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0365 - categorical_accuracy: 0.9883Epoch 00105: loss improved from 0.03741 to 0.03634, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0105_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0363 - categorical_accuracy: 0.9884 - val_loss: 0.0673 - val_categorical_accuracy: 0.9692\n",
      "Epoch 107/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0340 - categorical_accuracy: 0.9883Epoch 00106: loss improved from 0.03634 to 0.03530, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0106_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0353 - categorical_accuracy: 0.9871 - val_loss: 0.0670 - val_categorical_accuracy: 0.9744\n",
      "Epoch 108/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0364 - categorical_accuracy: 0.9896Epoch 00107: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0365 - categorical_accuracy: 0.9897 - val_loss: 0.0713 - val_categorical_accuracy: 0.9692\n",
      "Epoch 109/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0379 - categorical_accuracy: 0.9844Epoch 00108: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0376 - categorical_accuracy: 0.9846 - val_loss: 0.0670 - val_categorical_accuracy: 0.9744\n",
      "Epoch 110/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0348 - categorical_accuracy: 0.9909Epoch 00109: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0354 - categorical_accuracy: 0.9897 - val_loss: 0.0715 - val_categorical_accuracy: 0.9795\n",
      "Epoch 111/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0349 - categorical_accuracy: 0.9922Epoch 00110: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0356 - categorical_accuracy: 0.9910 - val_loss: 0.0924 - val_categorical_accuracy: 0.9641\n",
      "Epoch 112/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0356 - categorical_accuracy: 0.9883Epoch 00111: loss improved from 0.03530 to 0.03515, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0111_L-0.04.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0352 - categorical_accuracy: 0.9884 - val_loss: 0.0697 - val_categorical_accuracy: 0.9795\n",
      "Epoch 113/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0383 - categorical_accuracy: 0.9896Epoch 00112: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0378 - categorical_accuracy: 0.9897 - val_loss: 0.0684 - val_categorical_accuracy: 0.9744\n",
      "Epoch 114/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0349 - categorical_accuracy: 0.9909Epoch 00113: loss improved from 0.03515 to 0.03452, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0113_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0345 - categorical_accuracy: 0.9910 - val_loss: 0.0665 - val_categorical_accuracy: 0.9795\n",
      "Epoch 115/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0361 - categorical_accuracy: 0.9883Epoch 00114: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0358 - categorical_accuracy: 0.9884 - val_loss: 0.0680 - val_categorical_accuracy: 0.9795\n",
      "Epoch 116/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0344 - categorical_accuracy: 0.9883Epoch 00115: loss improved from 0.03452 to 0.03452, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0115_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0345 - categorical_accuracy: 0.9884 - val_loss: 0.0725 - val_categorical_accuracy: 0.9641\n",
      "Epoch 117/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0458 - categorical_accuracy: 0.9857Epoch 00116: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0453 - categorical_accuracy: 0.9858 - val_loss: 0.0680 - val_categorical_accuracy: 0.9744\n",
      "Epoch 118/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0422 - categorical_accuracy: 0.9844Epoch 00117: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0418 - categorical_accuracy: 0.9846 - val_loss: 0.0671 - val_categorical_accuracy: 0.9795\n",
      "Epoch 119/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0348 - categorical_accuracy: 0.9896Epoch 00118: loss improved from 0.03452 to 0.03443, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0118_L-0.03.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777/777 [==============================] - 6s - loss: 0.0344 - categorical_accuracy: 0.9897 - val_loss: 0.0690 - val_categorical_accuracy: 0.9590\n",
      "Epoch 120/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0399 - categorical_accuracy: 0.9844Epoch 00119: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0394 - categorical_accuracy: 0.9846 - val_loss: 0.1206 - val_categorical_accuracy: 0.9487\n",
      "Epoch 121/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0386 - categorical_accuracy: 0.9857Epoch 00120: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0384 - categorical_accuracy: 0.9858 - val_loss: 0.0749 - val_categorical_accuracy: 0.9744\n",
      "Epoch 122/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0320 - categorical_accuracy: 0.9922Epoch 00121: loss improved from 0.03443 to 0.03166, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0121_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0317 - categorical_accuracy: 0.9923 - val_loss: 0.0674 - val_categorical_accuracy: 0.9641\n",
      "Epoch 123/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0345 - categorical_accuracy: 0.9883Epoch 00122: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0341 - categorical_accuracy: 0.9884 - val_loss: 0.0666 - val_categorical_accuracy: 0.9692\n",
      "Epoch 124/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0354 - categorical_accuracy: 0.9909Epoch 00123: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0363 - categorical_accuracy: 0.9910 - val_loss: 0.0694 - val_categorical_accuracy: 0.9795\n",
      "Epoch 125/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0345 - categorical_accuracy: 0.9870Epoch 00124: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0342 - categorical_accuracy: 0.9871 - val_loss: 0.0666 - val_categorical_accuracy: 0.9692\n",
      "Epoch 126/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0363 - categorical_accuracy: 0.9883Epoch 00125: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0362 - categorical_accuracy: 0.9884 - val_loss: 0.0677 - val_categorical_accuracy: 0.9641\n",
      "Epoch 127/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0325 - categorical_accuracy: 0.9896Epoch 00126: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0322 - categorical_accuracy: 0.9897 - val_loss: 0.0664 - val_categorical_accuracy: 0.9590\n",
      "Epoch 128/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0268 - categorical_accuracy: 0.9935Epoch 00127: loss improved from 0.03166 to 0.03016, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0127_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0302 - categorical_accuracy: 0.9923 - val_loss: 0.0726 - val_categorical_accuracy: 0.9744\n",
      "Epoch 129/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0364 - categorical_accuracy: 0.9857Epoch 00128: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0390 - categorical_accuracy: 0.9846 - val_loss: 0.0779 - val_categorical_accuracy: 0.9590\n",
      "Epoch 130/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0396 - categorical_accuracy: 0.9870Epoch 00129: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0398 - categorical_accuracy: 0.9871 - val_loss: 0.0717 - val_categorical_accuracy: 0.9744\n",
      "Epoch 131/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0321 - categorical_accuracy: 0.9896Epoch 00130: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0319 - categorical_accuracy: 0.9897 - val_loss: 0.0675 - val_categorical_accuracy: 0.9641\n",
      "Epoch 132/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0312 - categorical_accuracy: 0.9870Epoch 00131: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0326 - categorical_accuracy: 0.9858 - val_loss: 0.0758 - val_categorical_accuracy: 0.9744\n",
      "Epoch 133/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0352 - categorical_accuracy: 0.9857Epoch 00132: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0353 - categorical_accuracy: 0.9858 - val_loss: 0.0729 - val_categorical_accuracy: 0.9641\n",
      "Epoch 134/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0334 - categorical_accuracy: 0.9883Epoch 00133: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0330 - categorical_accuracy: 0.9884 - val_loss: 0.0675 - val_categorical_accuracy: 0.9641\n",
      "Epoch 135/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0318 - categorical_accuracy: 0.9883Epoch 00134: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0337 - categorical_accuracy: 0.9871 - val_loss: 0.0701 - val_categorical_accuracy: 0.9590\n",
      "Epoch 136/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0355 - categorical_accuracy: 0.9870Epoch 00135: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0352 - categorical_accuracy: 0.9871 - val_loss: 0.0662 - val_categorical_accuracy: 0.9744\n",
      "Epoch 137/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0344 - categorical_accuracy: 0.9896Epoch 00136: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0346 - categorical_accuracy: 0.9897 - val_loss: 0.0701 - val_categorical_accuracy: 0.9692\n",
      "Epoch 138/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0393 - categorical_accuracy: 0.9870Epoch 00137: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0388 - categorical_accuracy: 0.9871 - val_loss: 0.0678 - val_categorical_accuracy: 0.9744\n",
      "Epoch 139/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0319 - categorical_accuracy: 0.9896Epoch 00138: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0316 - categorical_accuracy: 0.9897 - val_loss: 0.0783 - val_categorical_accuracy: 0.9641\n",
      "Epoch 140/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0345 - categorical_accuracy: 0.9857Epoch 00139: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0341 - categorical_accuracy: 0.9858 - val_loss: 0.0691 - val_categorical_accuracy: 0.9641\n",
      "Epoch 141/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0331 - categorical_accuracy: 0.9896Epoch 00140: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0327 - categorical_accuracy: 0.9897 - val_loss: 0.0658 - val_categorical_accuracy: 0.9692\n",
      "Epoch 142/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0312 - categorical_accuracy: 0.9896Epoch 00141: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0311 - categorical_accuracy: 0.9897 - val_loss: 0.0773 - val_categorical_accuracy: 0.9692\n",
      "Epoch 143/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0357 - categorical_accuracy: 0.9805Epoch 00142: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0367 - categorical_accuracy: 0.9794 - val_loss: 0.0834 - val_categorical_accuracy: 0.9692\n",
      "Epoch 144/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0373 - categorical_accuracy: 0.9870Epoch 00143: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0376 - categorical_accuracy: 0.9871 - val_loss: 0.1888 - val_categorical_accuracy: 0.9436\n",
      "Epoch 145/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0567 - categorical_accuracy: 0.9792Epoch 00144: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0567 - categorical_accuracy: 0.9794 - val_loss: 0.0681 - val_categorical_accuracy: 0.9795\n",
      "Epoch 146/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0383 - categorical_accuracy: 0.9870Epoch 00145: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0379 - categorical_accuracy: 0.9871 - val_loss: 0.0752 - val_categorical_accuracy: 0.9641\n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/777 [============================>.] - ETA: 0s - loss: 0.0353 - categorical_accuracy: 0.9909Epoch 00146: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0354 - categorical_accuracy: 0.9910 - val_loss: 0.0700 - val_categorical_accuracy: 0.9795\n",
      "Epoch 148/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0330 - categorical_accuracy: 0.9883Epoch 00147: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0331 - categorical_accuracy: 0.9884 - val_loss: 0.0847 - val_categorical_accuracy: 0.9692\n",
      "Epoch 149/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0258 - categorical_accuracy: 0.9909Epoch 00148: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0329 - categorical_accuracy: 0.9884 - val_loss: 0.0678 - val_categorical_accuracy: 0.9590\n",
      "Epoch 150/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0492 - categorical_accuracy: 0.9779Epoch 00149: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0487 - categorical_accuracy: 0.9781 - val_loss: 0.0759 - val_categorical_accuracy: 0.9744\n",
      "Epoch 151/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0330 - categorical_accuracy: 0.9870Epoch 00150: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0332 - categorical_accuracy: 0.9871 - val_loss: 0.0661 - val_categorical_accuracy: 0.9641\n",
      "Epoch 152/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0384 - categorical_accuracy: 0.9857Epoch 00151: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0390 - categorical_accuracy: 0.9846 - val_loss: 0.0691 - val_categorical_accuracy: 0.9795\n",
      "Epoch 153/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0332 - categorical_accuracy: 0.9935Epoch 00152: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0329 - categorical_accuracy: 0.9936 - val_loss: 0.0712 - val_categorical_accuracy: 0.9641\n",
      "Epoch 154/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0366 - categorical_accuracy: 0.9857Epoch 00153: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0438 - categorical_accuracy: 0.9846 - val_loss: 0.0731 - val_categorical_accuracy: 0.9641\n",
      "Epoch 155/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0355 - categorical_accuracy: 0.9857Epoch 00154: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0351 - categorical_accuracy: 0.9858 - val_loss: 0.0720 - val_categorical_accuracy: 0.9641\n",
      "Epoch 156/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0303 - categorical_accuracy: 0.9922Epoch 00155: loss improved from 0.03016 to 0.03012, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0155_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0301 - categorical_accuracy: 0.9923 - val_loss: 0.0754 - val_categorical_accuracy: 0.9692\n",
      "Epoch 157/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0311 - categorical_accuracy: 0.9922Epoch 00156: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0308 - categorical_accuracy: 0.9923 - val_loss: 0.0662 - val_categorical_accuracy: 0.9744\n",
      "Epoch 158/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0324 - categorical_accuracy: 0.9896Epoch 00157: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0321 - categorical_accuracy: 0.9897 - val_loss: 0.0770 - val_categorical_accuracy: 0.9590\n",
      "Epoch 159/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0334 - categorical_accuracy: 0.9857Epoch 00158: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0331 - categorical_accuracy: 0.9858 - val_loss: 0.0688 - val_categorical_accuracy: 0.9692\n",
      "Epoch 160/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0314 - categorical_accuracy: 0.9909Epoch 00159: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0326 - categorical_accuracy: 0.9897 - val_loss: 0.0724 - val_categorical_accuracy: 0.9692\n",
      "Epoch 161/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0303 - categorical_accuracy: 0.9896Epoch 00160: loss improved from 0.03012 to 0.03000, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0160_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0300 - categorical_accuracy: 0.9897 - val_loss: 0.0660 - val_categorical_accuracy: 0.9744\n",
      "Epoch 162/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0273 - categorical_accuracy: 0.9922Epoch 00161: loss improved from 0.03000 to 0.02751, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0161_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0275 - categorical_accuracy: 0.9923 - val_loss: 0.0700 - val_categorical_accuracy: 0.9744\n",
      "Epoch 163/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0302 - categorical_accuracy: 0.9922Epoch 00162: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0298 - categorical_accuracy: 0.9923 - val_loss: 0.1074 - val_categorical_accuracy: 0.9487\n",
      "Epoch 164/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0415 - categorical_accuracy: 0.9818Epoch 00163: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0416 - categorical_accuracy: 0.9820 - val_loss: 0.0679 - val_categorical_accuracy: 0.9744\n",
      "Epoch 165/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0345 - categorical_accuracy: 0.9870Epoch 00164: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0341 - categorical_accuracy: 0.9871 - val_loss: 0.0795 - val_categorical_accuracy: 0.9744\n",
      "Epoch 166/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0295 - categorical_accuracy: 0.9922Epoch 00165: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0293 - categorical_accuracy: 0.9923 - val_loss: 0.0718 - val_categorical_accuracy: 0.9692\n",
      "Epoch 167/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0327 - categorical_accuracy: 0.9883Epoch 00166: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0323 - categorical_accuracy: 0.9884 - val_loss: 0.1026 - val_categorical_accuracy: 0.9487\n",
      "Epoch 168/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0340 - categorical_accuracy: 0.9896Epoch 00167: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0337 - categorical_accuracy: 0.9897 - val_loss: 0.0712 - val_categorical_accuracy: 0.9641\n",
      "Epoch 169/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0293 - categorical_accuracy: 0.9896Epoch 00168: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0293 - categorical_accuracy: 0.9897 - val_loss: 0.0686 - val_categorical_accuracy: 0.9641\n",
      "Epoch 170/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0358 - categorical_accuracy: 0.9831Epoch 00169: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0356 - categorical_accuracy: 0.9833 - val_loss: 0.0887 - val_categorical_accuracy: 0.9590\n",
      "Epoch 171/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0298 - categorical_accuracy: 0.9922Epoch 00170: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0296 - categorical_accuracy: 0.9923 - val_loss: 0.0806 - val_categorical_accuracy: 0.9590\n",
      "Epoch 172/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0313 - categorical_accuracy: 0.9883Epoch 00171: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0310 - categorical_accuracy: 0.9884 - val_loss: 0.0805 - val_categorical_accuracy: 0.9692\n",
      "Epoch 173/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0316 - categorical_accuracy: 0.9883Epoch 00172: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0315 - categorical_accuracy: 0.9884 - val_loss: 0.0833 - val_categorical_accuracy: 0.9692\n",
      "Epoch 174/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0303 - categorical_accuracy: 0.9922Epoch 00173: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0300 - categorical_accuracy: 0.9923 - val_loss: 0.1033 - val_categorical_accuracy: 0.9692\n",
      "Epoch 175/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0408 - categorical_accuracy: 0.9896Epoch 00174: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0403 - categorical_accuracy: 0.9897 - val_loss: 0.0689 - val_categorical_accuracy: 0.9590\n",
      "Epoch 176/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0268 - categorical_accuracy: 0.9896Epoch 00175: loss improved from 0.02751 to 0.02665, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0175_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0266 - categorical_accuracy: 0.9897 - val_loss: 0.0971 - val_categorical_accuracy: 0.9590\n",
      "Epoch 177/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0273 - categorical_accuracy: 0.9883Epoch 00176: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0272 - categorical_accuracy: 0.9884 - val_loss: 0.0687 - val_categorical_accuracy: 0.9590\n",
      "Epoch 178/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0261 - categorical_accuracy: 0.9922Epoch 00177: loss improved from 0.02665 to 0.02612, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0177_L-0.03.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0261 - categorical_accuracy: 0.9923 - val_loss: 0.0675 - val_categorical_accuracy: 0.9641\n",
      "Epoch 179/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0275 - categorical_accuracy: 0.9922Epoch 00178: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0272 - categorical_accuracy: 0.9923 - val_loss: 0.0684 - val_categorical_accuracy: 0.9744\n",
      "Epoch 180/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0240 - categorical_accuracy: 0.9909Epoch 00179: loss improved from 0.02612 to 0.02376, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0179_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0238 - categorical_accuracy: 0.9910 - val_loss: 0.0810 - val_categorical_accuracy: 0.9744\n",
      "Epoch 181/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0261 - categorical_accuracy: 0.9948Epoch 00180: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0262 - categorical_accuracy: 0.9949 - val_loss: 0.0730 - val_categorical_accuracy: 0.9590\n",
      "Epoch 182/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0268 - categorical_accuracy: 0.9909Epoch 00181: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0265 - categorical_accuracy: 0.9910 - val_loss: 0.0762 - val_categorical_accuracy: 0.9641\n",
      "Epoch 183/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0280 - categorical_accuracy: 0.9896Epoch 00182: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0277 - categorical_accuracy: 0.9897 - val_loss: 0.0678 - val_categorical_accuracy: 0.9641\n",
      "Epoch 184/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0296 - categorical_accuracy: 0.9909Epoch 00183: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0293 - categorical_accuracy: 0.9910 - val_loss: 0.0762 - val_categorical_accuracy: 0.9641\n",
      "Epoch 185/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0285 - categorical_accuracy: 0.9896Epoch 00184: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0284 - categorical_accuracy: 0.9897 - val_loss: 0.0734 - val_categorical_accuracy: 0.9590\n",
      "Epoch 186/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0271 - categorical_accuracy: 0.9922Epoch 00185: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0268 - categorical_accuracy: 0.9923 - val_loss: 0.0681 - val_categorical_accuracy: 0.9590\n",
      "Epoch 187/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0269 - categorical_accuracy: 0.9909Epoch 00186: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0269 - categorical_accuracy: 0.9910 - val_loss: 0.0721 - val_categorical_accuracy: 0.9590\n",
      "Epoch 188/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0350 - categorical_accuracy: 0.9909Epoch 00187: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0346 - categorical_accuracy: 0.9910 - val_loss: 0.0760 - val_categorical_accuracy: 0.9744\n",
      "Epoch 189/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0251 - categorical_accuracy: 0.9922Epoch 00188: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0248 - categorical_accuracy: 0.9923 - val_loss: 0.0700 - val_categorical_accuracy: 0.9641\n",
      "Epoch 190/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0239 - categorical_accuracy: 0.9896Epoch 00189: loss improved from 0.02376 to 0.02365, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0189_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0236 - categorical_accuracy: 0.9897 - val_loss: 0.0686 - val_categorical_accuracy: 0.9692\n",
      "Epoch 191/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0306 - categorical_accuracy: 0.9883Epoch 00190: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0302 - categorical_accuracy: 0.9884 - val_loss: 0.0777 - val_categorical_accuracy: 0.9590\n",
      "Epoch 192/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0235 - categorical_accuracy: 0.9922Epoch 00191: loss improved from 0.02365 to 0.02320, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0191_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0232 - categorical_accuracy: 0.9923 - val_loss: 0.0741 - val_categorical_accuracy: 0.9641\n",
      "Epoch 193/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0277 - categorical_accuracy: 0.9883Epoch 00192: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0274 - categorical_accuracy: 0.9884 - val_loss: 0.0788 - val_categorical_accuracy: 0.9692\n",
      "Epoch 194/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0318 - categorical_accuracy: 0.9883Epoch 00193: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0314 - categorical_accuracy: 0.9884 - val_loss: 0.0993 - val_categorical_accuracy: 0.9538\n",
      "Epoch 195/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0392 - categorical_accuracy: 0.9831Epoch 00194: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0388 - categorical_accuracy: 0.9833 - val_loss: 0.0837 - val_categorical_accuracy: 0.9641\n",
      "Epoch 196/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0283 - categorical_accuracy: 0.9909Epoch 00195: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0280 - categorical_accuracy: 0.9910 - val_loss: 0.0901 - val_categorical_accuracy: 0.9744\n",
      "Epoch 197/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0293 - categorical_accuracy: 0.9896Epoch 00196: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0289 - categorical_accuracy: 0.9897 - val_loss: 0.0826 - val_categorical_accuracy: 0.9590\n",
      "Epoch 198/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0345 - categorical_accuracy: 0.9844Epoch 00197: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0345 - categorical_accuracy: 0.9846 - val_loss: 0.1135 - val_categorical_accuracy: 0.9487\n",
      "Epoch 199/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0282 - categorical_accuracy: 0.9896Epoch 00198: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0279 - categorical_accuracy: 0.9897 - val_loss: 0.0709 - val_categorical_accuracy: 0.9641\n",
      "Epoch 200/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9922Epoch 00199: loss improved from 0.02320 to 0.02212, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0199_L-0.02.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777/777 [==============================] - 6s - loss: 0.0221 - categorical_accuracy: 0.9910 - val_loss: 0.0750 - val_categorical_accuracy: 0.9641\n",
      "Epoch 201/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0232 - categorical_accuracy: 0.9909Epoch 00200: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0229 - categorical_accuracy: 0.9910 - val_loss: 0.1024 - val_categorical_accuracy: 0.9590\n",
      "Epoch 202/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0331 - categorical_accuracy: 0.9857Epoch 00201: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0329 - categorical_accuracy: 0.9858 - val_loss: 0.0665 - val_categorical_accuracy: 0.9744\n",
      "Epoch 203/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0225 - categorical_accuracy: 0.9922Epoch 00202: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0222 - categorical_accuracy: 0.9923 - val_loss: 0.0740 - val_categorical_accuracy: 0.9590\n",
      "Epoch 204/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0236 - categorical_accuracy: 0.9909Epoch 00203: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0233 - categorical_accuracy: 0.9910 - val_loss: 0.0680 - val_categorical_accuracy: 0.9692\n",
      "Epoch 205/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0225 - categorical_accuracy: 0.9909Epoch 00204: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0234 - categorical_accuracy: 0.9910 - val_loss: 0.0723 - val_categorical_accuracy: 0.9590\n",
      "Epoch 206/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0216 - categorical_accuracy: 0.9922Epoch 00205: loss improved from 0.02212 to 0.02147, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0205_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0215 - categorical_accuracy: 0.9923 - val_loss: 0.0742 - val_categorical_accuracy: 0.9641\n",
      "Epoch 207/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0237 - categorical_accuracy: 0.9922Epoch 00206: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0235 - categorical_accuracy: 0.9923 - val_loss: 0.0910 - val_categorical_accuracy: 0.9590\n",
      "Epoch 208/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0226 - categorical_accuracy: 0.9922Epoch 00207: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0223 - categorical_accuracy: 0.9923 - val_loss: 0.0682 - val_categorical_accuracy: 0.9641\n",
      "Epoch 209/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9922Epoch 00208: loss improved from 0.02147 to 0.02075, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0208_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0208 - categorical_accuracy: 0.9923 - val_loss: 0.0683 - val_categorical_accuracy: 0.9641\n",
      "Epoch 210/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0213 - categorical_accuracy: 0.9935Epoch 00209: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0211 - categorical_accuracy: 0.9936 - val_loss: 0.1037 - val_categorical_accuracy: 0.9590\n",
      "Epoch 211/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0182 - categorical_accuracy: 0.9935Epoch 00210: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0210 - categorical_accuracy: 0.9923 - val_loss: 0.0753 - val_categorical_accuracy: 0.9692\n",
      "Epoch 212/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0296 - categorical_accuracy: 0.9896Epoch 00211: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0308 - categorical_accuracy: 0.9884 - val_loss: 0.0848 - val_categorical_accuracy: 0.9590\n",
      "Epoch 213/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0333 - categorical_accuracy: 0.9883Epoch 00212: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0329 - categorical_accuracy: 0.9884 - val_loss: 0.0815 - val_categorical_accuracy: 0.9692\n",
      "Epoch 214/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0248 - categorical_accuracy: 0.9909Epoch 00213: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0246 - categorical_accuracy: 0.9910 - val_loss: 0.0768 - val_categorical_accuracy: 0.9590\n",
      "Epoch 215/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0226 - categorical_accuracy: 0.9896Epoch 00214: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0223 - categorical_accuracy: 0.9897 - val_loss: 0.0757 - val_categorical_accuracy: 0.9692\n",
      "Epoch 216/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0278 - categorical_accuracy: 0.9870Epoch 00215: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0276 - categorical_accuracy: 0.9871 - val_loss: 0.0866 - val_categorical_accuracy: 0.9641\n",
      "Epoch 217/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0363 - categorical_accuracy: 0.9870Epoch 00216: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0360 - categorical_accuracy: 0.9871 - val_loss: 0.1220 - val_categorical_accuracy: 0.9436\n",
      "Epoch 218/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0531 - categorical_accuracy: 0.9831Epoch 00217: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0527 - categorical_accuracy: 0.9833 - val_loss: 0.0630 - val_categorical_accuracy: 0.9744\n",
      "Epoch 219/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0416 - categorical_accuracy: 0.9870Epoch 00218: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0415 - categorical_accuracy: 0.9871 - val_loss: 0.0676 - val_categorical_accuracy: 0.9692\n",
      "Epoch 220/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0330 - categorical_accuracy: 0.9883Epoch 00219: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0330 - categorical_accuracy: 0.9884 - val_loss: 0.0733 - val_categorical_accuracy: 0.9641\n",
      "Epoch 221/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0300 - categorical_accuracy: 0.9844Epoch 00220: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0297 - categorical_accuracy: 0.9846 - val_loss: 0.0829 - val_categorical_accuracy: 0.9590\n",
      "Epoch 222/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0255 - categorical_accuracy: 0.9922Epoch 00221: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0295 - categorical_accuracy: 0.9910 - val_loss: 0.0680 - val_categorical_accuracy: 0.9744\n",
      "Epoch 223/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0248 - categorical_accuracy: 0.9883Epoch 00222: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0275 - categorical_accuracy: 0.9871 - val_loss: 0.0847 - val_categorical_accuracy: 0.9641\n",
      "Epoch 224/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0291 - categorical_accuracy: 0.9896Epoch 00223: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0288 - categorical_accuracy: 0.9897 - val_loss: 0.0880 - val_categorical_accuracy: 0.9692\n",
      "Epoch 225/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0187 - categorical_accuracy: 0.9948Epoch 00224: loss improved from 0.02075 to 0.01864, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0224_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0186 - categorical_accuracy: 0.9949 - val_loss: 0.0721 - val_categorical_accuracy: 0.9692\n",
      "Epoch 226/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0219 - categorical_accuracy: 0.9922Epoch 00225: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0217 - categorical_accuracy: 0.9923 - val_loss: 0.0864 - val_categorical_accuracy: 0.9590\n",
      "Epoch 227/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0208 - categorical_accuracy: 0.9922Epoch 00226: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0207 - categorical_accuracy: 0.9923 - val_loss: 0.0707 - val_categorical_accuracy: 0.9641\n",
      "Epoch 228/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0203 - categorical_accuracy: 0.9922Epoch 00227: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0201 - categorical_accuracy: 0.9923 - val_loss: 0.0747 - val_categorical_accuracy: 0.9590\n",
      "Epoch 229/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0191 - categorical_accuracy: 0.9935Epoch 00228: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0189 - categorical_accuracy: 0.9936 - val_loss: 0.0715 - val_categorical_accuracy: 0.9744\n",
      "Epoch 230/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0177 - categorical_accuracy: 0.9948Epoch 00229: loss improved from 0.01864 to 0.01754, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0229_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0175 - categorical_accuracy: 0.9949 - val_loss: 0.0777 - val_categorical_accuracy: 0.9590\n",
      "Epoch 231/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0192 - categorical_accuracy: 0.9922Epoch 00230: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0191 - categorical_accuracy: 0.9923 - val_loss: 0.0757 - val_categorical_accuracy: 0.9692\n",
      "Epoch 232/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0183 - categorical_accuracy: 0.9948Epoch 00231: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0192 - categorical_accuracy: 0.9936 - val_loss: 0.0737 - val_categorical_accuracy: 0.9744\n",
      "Epoch 233/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0235 - categorical_accuracy: 0.9896Epoch 00232: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0233 - categorical_accuracy: 0.9897 - val_loss: 0.0735 - val_categorical_accuracy: 0.9744\n",
      "Epoch 234/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0208 - categorical_accuracy: 0.9935Epoch 00233: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0206 - categorical_accuracy: 0.9936 - val_loss: 0.0688 - val_categorical_accuracy: 0.9744\n",
      "Epoch 235/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0184 - categorical_accuracy: 0.9922Epoch 00234: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0182 - categorical_accuracy: 0.9923 - val_loss: 0.0690 - val_categorical_accuracy: 0.9641\n",
      "Epoch 236/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0188 - categorical_accuracy: 0.9922Epoch 00235: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0186 - categorical_accuracy: 0.9923 - val_loss: 0.0767 - val_categorical_accuracy: 0.9641\n",
      "Epoch 237/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0190 - categorical_accuracy: 0.9922Epoch 00236: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0190 - categorical_accuracy: 0.9923 - val_loss: 0.0841 - val_categorical_accuracy: 0.9590\n",
      "Epoch 238/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0184 - categorical_accuracy: 0.9948Epoch 00237: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0186 - categorical_accuracy: 0.9949 - val_loss: 0.0746 - val_categorical_accuracy: 0.9590\n",
      "Epoch 239/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0219 - categorical_accuracy: 0.9935Epoch 00238: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0227 - categorical_accuracy: 0.9923 - val_loss: 0.0863 - val_categorical_accuracy: 0.9641\n",
      "Epoch 240/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0208 - categorical_accuracy: 0.9922Epoch 00239: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0205 - categorical_accuracy: 0.9923 - val_loss: 0.0732 - val_categorical_accuracy: 0.9641\n",
      "Epoch 241/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0168 - categorical_accuracy: 0.9948Epoch 00240: loss improved from 0.01754 to 0.01663, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0240_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0166 - categorical_accuracy: 0.9949 - val_loss: 0.0809 - val_categorical_accuracy: 0.9641\n",
      "Epoch 242/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0225 - categorical_accuracy: 0.9883Epoch 00241: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0223 - categorical_accuracy: 0.9884 - val_loss: 0.0761 - val_categorical_accuracy: 0.9641\n",
      "Epoch 243/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0209 - categorical_accuracy: 0.9922Epoch 00242: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0207 - categorical_accuracy: 0.9923 - val_loss: 0.0837 - val_categorical_accuracy: 0.9692\n",
      "Epoch 244/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0169 - categorical_accuracy: 0.9974Epoch 00243: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0199 - categorical_accuracy: 0.9961 - val_loss: 0.0716 - val_categorical_accuracy: 0.9692\n",
      "Epoch 245/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0319 - categorical_accuracy: 0.9857Epoch 00244: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0316 - categorical_accuracy: 0.9858 - val_loss: 0.0818 - val_categorical_accuracy: 0.9641\n",
      "Epoch 246/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0188 - categorical_accuracy: 0.9948Epoch 00245: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0194 - categorical_accuracy: 0.9949 - val_loss: 0.0908 - val_categorical_accuracy: 0.9641\n",
      "Epoch 247/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0326 - categorical_accuracy: 0.9883Epoch 00246: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0322 - categorical_accuracy: 0.9884 - val_loss: 0.1195 - val_categorical_accuracy: 0.9487\n",
      "Epoch 248/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0316 - categorical_accuracy: 0.9909Epoch 00247: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0312 - categorical_accuracy: 0.9910 - val_loss: 0.0709 - val_categorical_accuracy: 0.9692\n",
      "Epoch 249/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0312 - categorical_accuracy: 0.9909Epoch 00248: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0308 - categorical_accuracy: 0.9910 - val_loss: 0.0743 - val_categorical_accuracy: 0.9692\n",
      "Epoch 250/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0237 - categorical_accuracy: 0.9922Epoch 00249: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0234 - categorical_accuracy: 0.9923 - val_loss: 0.1046 - val_categorical_accuracy: 0.9590\n",
      "Epoch 251/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0262 - categorical_accuracy: 0.9909Epoch 00250: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0259 - categorical_accuracy: 0.9910 - val_loss: 0.0735 - val_categorical_accuracy: 0.9795\n",
      "Epoch 252/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0179 - categorical_accuracy: 0.9935Epoch 00251: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0177 - categorical_accuracy: 0.9936 - val_loss: 0.0709 - val_categorical_accuracy: 0.9744\n",
      "Epoch 253/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0170 - categorical_accuracy: 0.9935Epoch 00252: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0168 - categorical_accuracy: 0.9936 - val_loss: 0.0847 - val_categorical_accuracy: 0.9641\n",
      "Epoch 254/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0173 - categorical_accuracy: 0.9935Epoch 00253: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0171 - categorical_accuracy: 0.9936 - val_loss: 0.0722 - val_categorical_accuracy: 0.9692\n",
      "Epoch 255/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/777 [============================>.] - ETA: 0s - loss: 0.0189 - categorical_accuracy: 0.9922Epoch 00254: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0202 - categorical_accuracy: 0.9923 - val_loss: 0.0773 - val_categorical_accuracy: 0.9692\n",
      "Epoch 256/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0203 - categorical_accuracy: 0.9922Epoch 00255: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0207 - categorical_accuracy: 0.9923 - val_loss: 0.0825 - val_categorical_accuracy: 0.9641\n",
      "Epoch 257/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0176 - categorical_accuracy: 0.9948Epoch 00256: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0188 - categorical_accuracy: 0.9936 - val_loss: 0.0851 - val_categorical_accuracy: 0.9641\n",
      "Epoch 258/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0189 - categorical_accuracy: 0.9922Epoch 00257: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0190 - categorical_accuracy: 0.9923 - val_loss: 0.0685 - val_categorical_accuracy: 0.9744\n",
      "Epoch 259/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0152 - categorical_accuracy: 0.9948Epoch 00258: loss improved from 0.01663 to 0.01505, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0258_L-0.02.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0151 - categorical_accuracy: 0.9949 - val_loss: 0.0834 - val_categorical_accuracy: 0.9641\n",
      "Epoch 260/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0165 - categorical_accuracy: 0.9935Epoch 00259: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0163 - categorical_accuracy: 0.9936 - val_loss: 0.0745 - val_categorical_accuracy: 0.9692\n",
      "Epoch 261/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9948Epoch 00260: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0158 - categorical_accuracy: 0.9949 - val_loss: 0.0777 - val_categorical_accuracy: 0.9641\n",
      "Epoch 262/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0153 - categorical_accuracy: 0.9935Epoch 00261: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0154 - categorical_accuracy: 0.9936 - val_loss: 0.0717 - val_categorical_accuracy: 0.9744\n",
      "Epoch 263/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0140 - categorical_accuracy: 0.9948Epoch 00262: loss improved from 0.01505 to 0.01387, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0262_L-0.01.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0139 - categorical_accuracy: 0.9949 - val_loss: 0.0760 - val_categorical_accuracy: 0.9744\n",
      "Epoch 264/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0152 - categorical_accuracy: 0.9948Epoch 00263: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0150 - categorical_accuracy: 0.9949 - val_loss: 0.0793 - val_categorical_accuracy: 0.9641\n",
      "Epoch 265/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0149 - categorical_accuracy: 0.9974Epoch 00264: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0147 - categorical_accuracy: 0.9974 - val_loss: 0.0734 - val_categorical_accuracy: 0.9641\n",
      "Epoch 266/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0152 - categorical_accuracy: 0.9935Epoch 00265: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0169 - categorical_accuracy: 0.9923 - val_loss: 0.0833 - val_categorical_accuracy: 0.9590\n",
      "Epoch 267/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0258 - categorical_accuracy: 0.9896Epoch 00266: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0255 - categorical_accuracy: 0.9897 - val_loss: 0.0675 - val_categorical_accuracy: 0.9744\n",
      "Epoch 268/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0193 - categorical_accuracy: 0.9922Epoch 00267: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0194 - categorical_accuracy: 0.9923 - val_loss: 0.0815 - val_categorical_accuracy: 0.9590\n",
      "Epoch 269/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0162 - categorical_accuracy: 0.9935Epoch 00268: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0165 - categorical_accuracy: 0.9936 - val_loss: 0.0861 - val_categorical_accuracy: 0.9641\n",
      "Epoch 270/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0160 - categorical_accuracy: 0.9961Epoch 00269: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0161 - categorical_accuracy: 0.9961 - val_loss: 0.0819 - val_categorical_accuracy: 0.9590\n",
      "Epoch 271/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0151 - categorical_accuracy: 0.9974Epoch 00270: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0153 - categorical_accuracy: 0.9974 - val_loss: 0.0786 - val_categorical_accuracy: 0.9538\n",
      "Epoch 272/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0147 - categorical_accuracy: 0.9961Epoch 00271: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0152 - categorical_accuracy: 0.9961 - val_loss: 0.0739 - val_categorical_accuracy: 0.9590\n",
      "Epoch 273/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0213 - categorical_accuracy: 0.9896Epoch 00272: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0211 - categorical_accuracy: 0.9897 - val_loss: 0.0756 - val_categorical_accuracy: 0.9641\n",
      "Epoch 274/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0191 - categorical_accuracy: 0.9922Epoch 00273: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0189 - categorical_accuracy: 0.9923 - val_loss: 0.0772 - val_categorical_accuracy: 0.9641\n",
      "Epoch 275/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0136 - categorical_accuracy: 0.9935Epoch 00274: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0139 - categorical_accuracy: 0.9936 - val_loss: 0.0704 - val_categorical_accuracy: 0.9692\n",
      "Epoch 276/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0172 - categorical_accuracy: 0.9935Epoch 00275: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0170 - categorical_accuracy: 0.9936 - val_loss: 0.0707 - val_categorical_accuracy: 0.9692\n",
      "Epoch 277/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0143 - categorical_accuracy: 0.9961Epoch 00276: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0141 - categorical_accuracy: 0.9961 - val_loss: 0.0758 - val_categorical_accuracy: 0.9641\n",
      "Epoch 278/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0144 - categorical_accuracy: 0.9948Epoch 00277: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0142 - categorical_accuracy: 0.9949 - val_loss: 0.0737 - val_categorical_accuracy: 0.9641\n",
      "Epoch 279/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9935Epoch 00278: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0156 - categorical_accuracy: 0.9936 - val_loss: 0.0693 - val_categorical_accuracy: 0.9744\n",
      "Epoch 280/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0138 - categorical_accuracy: 0.9961Epoch 00279: loss improved from 0.01387 to 0.01366, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0279_L-0.01.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0137 - categorical_accuracy: 0.9961 - val_loss: 0.0720 - val_categorical_accuracy: 0.9692\n",
      "Epoch 281/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0141 - categorical_accuracy: 0.9935Epoch 00280: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0139 - categorical_accuracy: 0.9936 - val_loss: 0.0845 - val_categorical_accuracy: 0.9641\n",
      "Epoch 282/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0142 - categorical_accuracy: 0.9974Epoch 00281: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0140 - categorical_accuracy: 0.9974 - val_loss: 0.0712 - val_categorical_accuracy: 0.9744\n",
      "Epoch 283/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0131 - categorical_accuracy: 0.9948Epoch 00282: loss improved from 0.01366 to 0.01316, saving model to v1_FCN/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0282_L-0.01.hdf5\n",
      "777/777 [==============================] - 6s - loss: 0.0132 - categorical_accuracy: 0.9949 - val_loss: 0.0800 - val_categorical_accuracy: 0.9641\n",
      "Epoch 284/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0157 - categorical_accuracy: 0.9948Epoch 00283: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0155 - categorical_accuracy: 0.9949 - val_loss: 0.0723 - val_categorical_accuracy: 0.9692\n",
      "Epoch 285/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0155 - categorical_accuracy: 0.9922Epoch 00284: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0154 - categorical_accuracy: 0.9923 - val_loss: 0.0926 - val_categorical_accuracy: 0.9641\n",
      "Epoch 286/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0163 - categorical_accuracy: 0.9948Epoch 00285: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0161 - categorical_accuracy: 0.9949 - val_loss: 0.0709 - val_categorical_accuracy: 0.9692\n",
      "Epoch 287/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0164 - categorical_accuracy: 0.9935Epoch 00286: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0162 - categorical_accuracy: 0.9936 - val_loss: 0.0696 - val_categorical_accuracy: 0.9692\n",
      "Epoch 288/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0147 - categorical_accuracy: 0.9948Epoch 00287: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0146 - categorical_accuracy: 0.9949 - val_loss: 0.0841 - val_categorical_accuracy: 0.9641\n",
      "Epoch 289/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0153 - categorical_accuracy: 0.9948Epoch 00288: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0151 - categorical_accuracy: 0.9949 - val_loss: 0.0858 - val_categorical_accuracy: 0.9641\n",
      "Epoch 290/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0140 - categorical_accuracy: 0.9961Epoch 00289: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0139 - categorical_accuracy: 0.9961 - val_loss: 0.0707 - val_categorical_accuracy: 0.9641\n",
      "Epoch 291/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0134 - categorical_accuracy: 0.9948Epoch 00290: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0134 - categorical_accuracy: 0.9949 - val_loss: 0.0934 - val_categorical_accuracy: 0.9538\n",
      "Epoch 292/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0186 - categorical_accuracy: 0.9935Epoch 00291: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0190 - categorical_accuracy: 0.9936 - val_loss: 0.0709 - val_categorical_accuracy: 0.9744\n",
      "Epoch 293/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0191 - categorical_accuracy: 0.9922Epoch 00292: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0189 - categorical_accuracy: 0.9923 - val_loss: 0.0872 - val_categorical_accuracy: 0.9744\n",
      "Epoch 294/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0183 - categorical_accuracy: 0.9948Epoch 00293: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0181 - categorical_accuracy: 0.9949 - val_loss: 0.0908 - val_categorical_accuracy: 0.9590\n",
      "Epoch 295/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9948Epoch 00294: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0156 - categorical_accuracy: 0.9949 - val_loss: 0.0738 - val_categorical_accuracy: 0.9692\n",
      "Epoch 296/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0142 - categorical_accuracy: 0.9948Epoch 00295: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0141 - categorical_accuracy: 0.9949 - val_loss: 0.1107 - val_categorical_accuracy: 0.9538\n",
      "Epoch 297/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0220 - categorical_accuracy: 0.9896Epoch 00296: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0217 - categorical_accuracy: 0.9897 - val_loss: 0.0790 - val_categorical_accuracy: 0.9590\n",
      "Epoch 298/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0173 - categorical_accuracy: 0.9948Epoch 00297: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0171 - categorical_accuracy: 0.9949 - val_loss: 0.0807 - val_categorical_accuracy: 0.9692\n",
      "Epoch 299/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0136 - categorical_accuracy: 0.9961Epoch 00298: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0135 - categorical_accuracy: 0.9961 - val_loss: 0.0762 - val_categorical_accuracy: 0.9590\n",
      "Epoch 300/300\n",
      "768/777 [============================>.] - ETA: 0s - loss: 0.0132 - categorical_accuracy: 0.9948Epoch 00299: loss did not improve\n",
      "777/777 [==============================] - 6s - loss: 0.0136 - categorical_accuracy: 0.9949 - val_loss: 0.0732 - val_categorical_accuracy: 0.9744\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAEYCAYAAADPrtzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22832e0d748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## First run that included alot of silences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model : v1_FCN/Logs/v1_FCN_model_v1_1.json\n",
      "Saved weights : v1_FCN/Logs/v1_FCN_weights_v1_1.h5\n"
     ]
    }
   ],
   "source": [
    "save_or_load = 'save'\n",
    "model_path = Weights_path+Archi_dir[:-1]+\"_model_v1_1.json\"\n",
    "weights_path = Weights_path+Archi_dir[:-1]+\"_weights_v1_1.h5\"\n",
    "if save_or_load == 'save':\n",
    "    save_model(v1_1, model_path, weights_path)\n",
    "elif save_or_load == 'load':\n",
    "    _ = load_model(model_path, 'path', weights_path, 'final')\n",
    "    _.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1_2\n",
    "    use v1_1 architecture to learn limited data of Data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from path : v1_2_FCN_limited/Logs/v1_2_FCN_limited_model_v1_1.json\n",
      "Loaded weights         : v1_2_FCN_limited/Checkpoint_Model_Weights/v1_1/weights_v1_1_Epoch-0282_L-0.01.hdf5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 129, 48, 1)        0         \n",
      "_________________________________________________________________\n",
      "0_Conv2D (Conv2D)            (None, 129, 48, 64)       640       \n",
      "_________________________________________________________________\n",
      "1_Conv2D (Conv2D)            (None, 129, 48, 64)       36928     \n",
      "_________________________________________________________________\n",
      "1_Pool (MaxPooling2D)        (None, 64, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "2_Conv2D (Conv2D)            (None, 64, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "GlobalPool (GlobalAveragePoo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "3_Dense (Dense)              (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "4_Dense (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "5_Output (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 107,798\n",
      "Trainable params: 107,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "save_or_load = 'save'\n",
    "model_path = Weights_path+Archi_dir[:-1]+\"_model_v1_1.json\"\n",
    "weights_path = Ckpt_Mod_Weights_fold+\"v1_1/weights_v1_1_Epoch-0282_L-0.01.hdf5\"\n",
    "v1_2 = load_model(model_path, 'path', weights_path)\n",
    "v1_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40739, 8144, 32595)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_m,count_f = 0,0\n",
    "y_train,y_val = [],[]\n",
    "for idx in range(len(Y_train)):\n",
    "    x,y = X\n",
    "    if y[0]==1 : \n",
    "        count_m +=1\n",
    "        if count_m >= len(Y_train)//10: y_val.append(y)\n",
    "        else: y_train.append(y)\n",
    "    else : \n",
    "        count_f += 1\n",
    "        if count_f >= len(Y_train)//10: y_val.append(y)\n",
    "        else: y_train.append(y)\n",
    "len(Y_train), len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.001\n",
      "ckpt_path :  v1_2_FCN_limited/Checkpoint_Model_Weights/v1_2/weights_v1_2_Epoch-{epoch:04d}_VCA-{val_categorical_accuracy:.2f}.hdf5 \n",
      "\n",
      "Train on 4073 samples, validate on 36666 samples\n",
      "Epoch 1/60\n",
      " 992/4073 [======>.......................] - ETA: 26s - loss: 0.3683 - categorical_accuracy: 0.8700\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "######################## Training Parameters ###############################\n",
    "learning_rate = 1e-3;   print('learning_rate',learning_rate)\n",
    "# adam_opt = Adam(lr=learning_rate, decay=decay)\n",
    "sgd_opt = SGD(lr=learning_rate, momentum=0.9, decay=decay)\n",
    "v1_2.compile(loss=categorical_crossentropy ,optimizer=sgd_opt, metrics=['categorical_accuracy'])\n",
    "######################## Checkpoints ###############################\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=50, min_lr=1e-6, cooldown=50, epsilon=1e-05, verbose=1)\n",
    "CkptFold_det = [  'v1_2',    Ckpt_Mod_Weights_fold, 'v1_2/']\n",
    "ModelCheckpoint_det = ['val_categorical_accuracy',     1,            True,              False,           1] \n",
    "ckpt = ckpt_saving(CkptFold_det, ModelCheckpoint_det, save_all=True)\n",
    "csv_log = CSVLogger(Weights_path+'v1_2_Trglog.txt', '\\t')\n",
    "plot_path = plot_path_dir+'v1_2.png'\n",
    "########################### Actual training ##################################\n",
    "try:\n",
    "    history_v1_2 = v1_2.fit(X_train[:len(Y_train)//10],Y_train[:len(Y_train)//10], \n",
    "                            batch_size=32, epochs=60, verbose=1, \n",
    "                             validation_split = 0., validation_data=(X_train[len(Y_train)//10:],Y_train[len(Y_train)//10:]), # None (X_val,Y_val) (X_dev,Y_dev)\n",
    "                             callbacks=[csv_log, ckpt] # reduce_lr\n",
    "                            )\n",
    "    plt.figure(figsize=(14,4))\n",
    "#     plt.subplot(1,2,1);plot_loss(history_v1_2, metric_list=['loss'], title='Loss', plot_path=plot_path)\n",
    "#     plt.subplot(1,2,2);plot_loss(history_v1_2, metric_list=['categorical_accuracy'], title='Accuracy', plot_path=plot_path)\n",
    "    plt.subplot(1,2,1);plot_loss(history_v1_2, metric_list=['loss','val_loss'], title='Loss', plot_path=plot_path)\n",
    "    plt.subplot(1,2,2);plot_loss(history_v1_2, metric_list=['categorical_accuracy','val_categorical_accuracy'], title='Accuracy', plot_path=plot_path)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_or_load = 'save'\n",
    "    model_path = Weights_path+Archi_dir[:-1]+\"_model_v1_2.json\"\n",
    "    weights_path = Weights_path+Archi_dir[:-1]+\"_weights_v1_2.h5\"\n",
    "    save_model(v1_2, model_path, weights_path)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nKeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
